{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p style=\"border: 1px solid #e7692c; border-left: 15px solid #e7692c; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c\">Tip.</strong> <a style=\"color: #000000;\" href=\"https://nbviewer.jupyter.org/github/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/Chapter01/ch1_nb1_build_and_train_neural_network_from_scratch.ipynb\" title=\"View with Jupyter Online\">Click here to view this notebook on <code>nbviewer.jupyter.org</code></a>. \n",
    "    <br/>These notebooks are better read there, as Github default viewer ignores some of the formatting and interactive content.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "    <tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #363636; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #e7692c;\">Hands-on</span> Computer Vision with TensorFlow 2</span><br/>by <em>Eliot Andres</em> & <em>Benjamin Planche</em> (Packt Pub.)</strong><br/><br/>\n",
    "        <strong>> Chapter 1: Computer Vision and Neural Networks</strong><br/>\n",
    "    </p>\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #e7692c;\">Notebook 1:</small><br/>Building and Training a Neural Network <br/>from Scratch</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #363636; text-align:justify; padding: 0 10px;\">\n",
    "    In the introductory chapter of the book, we presented what <em>computer vision</em> and <em>deep learning</em> are, and how <em>neural</em> networks work. To illustrate the latter, we described how to <strong>build a simple neural network from scratch</strong>, and how to <strong>apply it to a classification task</strong>.\n",
    "    <br/><br/>In this first notebook, we will therefore detail the related code snippets and results from the book.\n",
    "</p>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #e7692c; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c;\">Tip.</strong> The notebooks shared on this git repository illustrate some notions from the book \"<em><strong>Hands-on Computer Vision with TensorFlow 2</strong></em>\" written by Eliot Andres and Benjamin Planche, published by Packt. If you enjoyed the insights shared here, <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Learn more about the book!\"><strong>please consider acquiring the book!</strong></a>\n",
    "<br/><br/>\n",
    "The book provides further guidance for those eager to learn about computer vision and to harness the power of TensorFlow 2 and Keras to build efficient recognition systems for object detection, segmentation, video processing, smartphone applications, and more.</p>\n",
    "        </td>\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; width: 280px;\">\n",
    "    <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Learn more about the book!\" target=\"_blank\">\n",
    "        <img src=\"../banner_images/book_cover.png\" width=280>\n",
    "    </a>\n",
    "    <p style=\"background: #e7692c; color:#ffffff; padding: 10px; text-align:justify;\"><strong>Leverage deep learning to create powerful image processing apps with TensorFlow 2 and Keras. <br/></strong>Get the book for more insights!</p>\n",
    "    <ul style=\"height: 32px; white-space: nowrap; text-align: center; margin: 0px; padding: 0px; padding-top: 10px;\">\n",
    "    <li style=\"display: block;height: 100%;float: left;vertical-align: middle;margin: 0 25px 10px;padding: 0px;\">\n",
    "        <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Get the book on Amazon (paperback or Kindle version)!\" target=\"_blank\">\n",
    "        <img style=\"vertical-align: middle; max-width: 72px; max-height: 32px;\" src=\"../banner_images/logo_amazon.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    <li style=\"display: inline-block;height: 100%;vertical-align: middle;float: right;margin: -5px 25px 10px;padding: 0px;\">\n",
    "        <a href=\"https://www.packtpub.com/application-development/hands-computer-vision-tensorflow-2\" title=\"Get your Packt book (paperback, PDF, ePUB, or MOBI version)!\" target=\"_blank\">\n",
    "        <img style=\"vertical-align: middle; max-width: 72px; max-height: 32px;\" src=\"../banner_images/logo_packt.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    </ul>\n",
    "        </td>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy    # Uncomment this line if the numpy library has not bee installed yet.\n",
    "import numpy as np      # We use numpy to make vector and matrix computations easy.\n",
    "np.random.seed(42)      # Fixing the seed for the random number generation, to get reproducable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the Beginning: the Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the comparison to the original, biological neurons, we explained in the book how scientists developed a simple _model_ to simulate their behavior[$^1$](#ref).\n",
    "\n",
    "The code below was provided in the chapter, along the mathematical explanations for each operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(object):\n",
    "    \"\"\"\n",
    "    A simple artificial neuron, processing an input vector and returning a corresponding activation.\n",
    "    Args:\n",
    "        num_inputs (int): The input vector size / number of input values.\n",
    "        activation_function (callable): The activation function defining this neuron.\n",
    "    Attributes:\n",
    "        W (ndarray): The weight values for each input.\n",
    "        b (float): The bias value, added to the weighted sum.\n",
    "        activation_function (callable): The activation function computing the neuron's output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs, activation_function):\n",
    "        super().__init__()\n",
    "\n",
    "        # Randomly initializing the weight vector and the bias value (e.g., using a simplistic \n",
    "        # uniform distribution between -1 and 1):\n",
    "        self.W = np.random.uniform(size=num_inputs, low=-1., high=1.)\n",
    "        self.b = np.random.uniform(size=1, low=-1., high=1.)\n",
    "\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward the input signal through the neuron, returning its activation value.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(1, num_inputs)`\n",
    "        Returns:\n",
    "            activation (ndarray): The activation value, of shape `(1, layer_size)`.\n",
    "        \"\"\"\n",
    "        z = np.dot(x, self.W) + self.b\n",
    "        return self.activation_function(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class represents a simple artificial neuron, able to receive a vector of input values, to merge and process them before returning an activation value. We will now demonstrate how this model can be used.\n",
    "\n",
    "***Note:*** This class can also be found in [neuron.py](neuron.py).\n",
    "\n",
    "First, we instantiate our neuron. Let us create a ***perceptron*** (c.f. Chapter 1) taking 2 input values and using the _step_ function for computing its *activation*. Its weights and bias values are randomly set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron's random weights = [-0.25091976  0.90142861  0.46398788] , and random bias = [0.19731697]\n"
     ]
    }
   ],
   "source": [
    "# Perceptron input size:\n",
    "input_size = 3\n",
    "\n",
    "# Step function (returns 0 if y <= 0, or 1 if y > 0):\n",
    "step_function = lambda y: 0 if y <= 0 else 1\n",
    "\n",
    "# Instantiating the perceptron:\n",
    "perceptron = Neuron(num_inputs=input_size, activation_function=step_function)\n",
    "print(\"Perceptron's random weights = {} , and random bias = {}\".format(perceptron.W, perceptron.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly generate a random input vector of 3 values (i.e. a column-vector of (shape = `(1, 3)`), to be fed to our neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector : [[0.15601864 0.15599452 0.05808361]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(input_size).reshape(1, input_size)\n",
    "print(\"Input vector : {}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now feed our perceptron with this input and display the corresponding activation. We invite our readers to try different inputs or edit the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron's output value given `x` : 1\n"
     ]
    }
   ],
   "source": [
    "y = perceptron.forward(x)\n",
    "print(\"Perceptron's output value given `x` : {}\".format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this `Neuron` class, we implemented the mathematical model for neurons proposed by early A.I. scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layering Neurons Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the homonym section of Chapter 1, we presented how neurons can be organized into ***layers***. We introduced the following model, mathematically wrapping together the operations done by such a neural layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(object):\n",
    "    \"\"\"A simple fully-connected NN layer.\n",
    "    Args:\n",
    "        num_inputs (int): The input vector size / number of input values.\n",
    "        layer_size (int): The output vector size / number of neurons in the layer.\n",
    "        activation_function (callable): The activation function for this layer.\n",
    "    Attributes:\n",
    "        W (ndarray): The weight values for each input.\n",
    "        b (ndarray): The bias value, added to the weighted sum.\n",
    "        size (int): The layer size / number of neurons.\n",
    "        activation_function (callable): The activation function computing the neuron's output.\n",
    "        x (ndarray): The last provided input vector, stored for backpropagation.\n",
    "        y (ndarray): The corresponding output, also stored for backpropagation.\n",
    "        derivated_activation_function (callable): The corresponding derivated function for backpropagation.\n",
    "        dL_dW (ndarray): The derivative of the loss, with respect to the weights W.\n",
    "        dL_db (ndarray): The derivative of the loss, with respect to the bias b.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs, layer_size, activation_function, derivated_activation_function=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Randomly initializing the weight vector and the bias value (using a normal distribution this time):\n",
    "        self.W = np.random.standard_normal((num_inputs, layer_size))\n",
    "        self.b = np.random.standard_normal(layer_size)\n",
    "        self.size = layer_size\n",
    "\n",
    "        self.activation_function = activation_function\n",
    "        self.derivated_activation_function = derivated_activation_function\n",
    "        self.x, self.y = None, None\n",
    "        self.dL_dW, self.dL_db = None, None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward the input vector through the layer, returning its activation vector.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(batch_size, num_inputs)`\n",
    "        Returns:\n",
    "            activation (ndarray): The activation value, of shape `(batch_size, layer_size)`.\n",
    "        \"\"\"\n",
    "        z = np.dot(x, self.W) + self.b\n",
    "        self.y = self.activation_function(z)\n",
    "        self.x = x  # (we store the input and output values for back-propagation)\n",
    "        return self.y\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        \"\"\"\n",
    "        Back-propagate the loss, computing all the derivatives, storing those w.r.t. the layer parameters,\n",
    "        and returning the loss w.r.t. its inputs for further propagation.\n",
    "        Args:\n",
    "            dL_dy (ndarray): The loss derivative w.r.t. the layer's output (dL/dy = l'_{k+1}).\n",
    "        Returns:\n",
    "            dL_dx (ndarray): The loss derivative w.r.t. the layer's input (dL/dx).\n",
    "        \"\"\"\n",
    "        dy_dz = self.derivated_activation_function(self.y)  # = f'\n",
    "        dL_dz = (dL_dy * dy_dz) # dL/dz = dL/dy * dy/dz = l'_{k+1} * f'\n",
    "        dz_dw = self.x.T\n",
    "        dz_dx = self.W.T\n",
    "        dz_db = np.ones(dL_dy.shape[0]) # dz/db = d(W.x + b)/db = 0 + db/db = \"ones\"-vector\n",
    "\n",
    "        # Computing the derivatives with respect to the layer's parameters, and storing them for opt. optimization:\n",
    "        self.dL_dW = np.dot(dz_dw, dL_dz)\n",
    "        self.dL_db = np.dot(dz_db, dL_dz)\n",
    "\n",
    "        # Computing the derivative with respect to the input, to be passed to the previous layers (their `dL_dy`):\n",
    "        dL_dx = np.dot(dL_dz, dz_dx)\n",
    "        return dL_dx\n",
    "\n",
    "    def optimize(self, epsilon):\n",
    "        \"\"\"\n",
    "        Optimize the layer's parameters, using the stored derivative values.\n",
    "        Args:\n",
    "            epsilon (float): The learning rate.\n",
    "        \"\"\"\n",
    "        self.W -= epsilon * self.dL_dW\n",
    "        self.b -= epsilon * self.dL_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** This class can also be found in [fully_connected_layer.py](fully_connected_layer.py). \n",
    "\n",
    "Once again, let us quickly show how this *layer* can be used to process input values, one by one or stacked together into ***batches***. We instantiate a layer of 3 neurons (so 3 output values), taking 2 input values and applying this time the ***ReLU*** (Rectified Linear Unit) function for the activations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size    = 2\n",
    "num_neurons   = 3\n",
    "relu_function = lambda y: np.maximum(y, 0)\n",
    "\n",
    "layer = FullyConnectedLayer(num_inputs=input_size, layer_size=num_neurons, activation_function=relu_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly generate 2 random input vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector #1: [[-0.72101228 -0.4157107 ]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.uniform(-1, 1, 2).reshape(1, 2)\n",
    "print(\"Input vector #1: {}\".format(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector #2: [[-0.26727631 -0.08786003]]\n"
     ]
    }
   ],
   "source": [
    "x2 = np.random.uniform(-1, 1, 2).reshape(1, 2)\n",
    "print(\"Input vector #2: {}\".format(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our layer can either process them separetely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer's output value given `x1` : [[0.         0.4593046  1.61941647]]\n"
     ]
    }
   ],
   "source": [
    "y1 = layer.forward(x1)\n",
    "print(\"Layer's output value given `x1` : {}\".format(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer's output value given `x2` : [[0.         0.73048436 1.05288999]]\n"
     ]
    }
   ],
   "source": [
    "y2 = layer.forward(x2)\n",
    "print(\"Layer's output value given `x2` : {}\".format(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer's output value given `[x1, x2]` :\n",
      "[[0.         0.4593046  1.61941647]\n",
      " [0.         0.73048436 1.05288999]]\n"
     ]
    }
   ],
   "source": [
    "x12 = np.concatenate((x1, x2))  # stack of input vectors, of shape `(2, 2)`\n",
    "y12 = layer.forward(x12)\n",
    "print(\"Layer's output value given `[x1, x2]` :\\n{}\".format(y12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Complete Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of neural layers is to be stacked together to form a ***neural network*** able to perform non-linear predictions.\n",
    "\n",
    "Applying a ***gradient descent***, such a network can be trained to perform correct predictions (c.f. theory in Chapter 1). But for that, we need a ***loss*** function to evaluate the performance of the network (c.f. ***L2*** or ***cross-entropy*** losses introduced in Chapter 1), and we need to know how to *derive* all the operations performed by the network, to compute and propagate the gradients.\n",
    "\n",
    "In this section, we will present how a simple fully-connected neural network can be built. Let us assume we want our network to use the *sigmoid* function for the activation. We need to implement that function _and_ its derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):             # sigmoid function\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y\n",
    "\n",
    "\n",
    "def derivated_sigmoid(y):   # sigmoid derivative function\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to build a neural network for classification. We would use the *L2* or *cross-entropy* loss previously introduced. We should also implement them, along their derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_L2(pred, target):             # L2 loss function\n",
    "    return np.sum(np.square(pred - target)) / pred.shape[0] # opt. we divide by the batch size\n",
    "\n",
    "\n",
    "def derivated_loss_L2(pred, target):   # L2 derivative function\n",
    "    return 2 * (pred - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(pred, target):            # cross-entropy loss function\n",
    "    return -np.mean(np.multiply(np.log(pred), target) + np.multiply(np.log(1 - pred), (1 - target)))\n",
    "\n",
    "\n",
    "def derivated_binary_cross_entropy(pred, target):  # cross-entropy derivative function\n",
    "    return (pred - target) / (pred * (1 - pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the book, we should now connect everything together, building a class able to connect multiple neural layers together, able to to feed-forward data through these layers and back-propagate the loss' gradients for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(object):\n",
    "    \"\"\"A simple fully-connected NN.\n",
    "    Args:\n",
    "        num_inputs (int): The input vector size / number of input values.\n",
    "        num_outputs (int): The output vector size.\n",
    "        hidden_layers_sizes (list): A list of sizes for each hidden layer to add to the network\n",
    "        activation_function (callable): The activation function for all the layers\n",
    "        derivated_activation_function (callable): The derivated activation function\n",
    "        loss_function (callable): The loss function to train this network\n",
    "        derivated_loss_function (callable): The derivative of the loss function, for back-propagation\n",
    "    Attributes:\n",
    "        layers (list): The list of layers forming this simple network.\n",
    "        loss_function (callable): The loss function to train this network.\n",
    "        derivated_loss_function (callable): The derivative of the loss function, for back-propagation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_layers_sizes=(64, 32),\n",
    "                 activation_function=sigmoid, derivated_activation_function=derivated_sigmoid,\n",
    "                 loss_function=loss_L2, derivated_loss_function=derivated_loss_L2):\n",
    "        super().__init__()\n",
    "        # We build the list of layers composing the network, according to the provided arguments:\n",
    "        layer_sizes = [num_inputs, *hidden_layers_sizes, num_outputs]\n",
    "        self.layers = [\n",
    "            FullyConnectedLayer(layer_sizes[i], layer_sizes[i + 1], \n",
    "                                activation_function, derivated_activation_function)\n",
    "            for i in range(len(layer_sizes) - 1)]\n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.derivated_loss_function = derivated_loss_function\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward the input vector through the layers, returning the output vector.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(batch_size, num_inputs)`.\n",
    "        Returns:\n",
    "            activation (ndarray): The output activation value, of shape `(batch_size, layer_size)`.\n",
    "        \"\"\"\n",
    "        for layer in self.layers: # from the input layer to the output one\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Compute the output corresponding to input `x`, and return the index of the largest \n",
    "        output value.\n",
    "        Args:\n",
    "            x (ndarray): The input vector, of shape `(1, num_inputs)`.\n",
    "        Returns:\n",
    "            best_class (int): The predicted class ID.\n",
    "        \"\"\"\n",
    "        estimations = self.forward(x)\n",
    "        best_class = np.argmax(estimations)\n",
    "        return best_class\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        \"\"\"\n",
    "        Back-propagate the loss hrough the layers (require `forward()` to be called before).\n",
    "        Args:\n",
    "            dL_dy (ndarray): The loss derivative w.r.t. the network's output (dL/dy).\n",
    "        Returns:\n",
    "            dL_dx (ndarray): The loss derivative w.r.t. the network's input (dL/dx).\n",
    "        \"\"\"\n",
    "        for layer in reversed(self.layers): # from the output layer to the input one\n",
    "            dL_dy = layer.backward(dL_dy)\n",
    "        return dL_dy\n",
    "\n",
    "    def optimize(self, epsilon):\n",
    "        \"\"\"\n",
    "        Optimize the network parameters according to the stored gradients (require `backward()`\n",
    "        to be called before).\n",
    "        Args:\n",
    "            epsilon (float): The learning rate.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:             # the order doesn't matter here\n",
    "            layer.optimize(epsilon)\n",
    "\n",
    "    def evaluate_accuracy(self, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Given a dataset and its ground-truth labels, evaluate the current accuracy of the network.\n",
    "        Args:\n",
    "            X_val (ndarray): The input validation dataset.\n",
    "            y_val (ndarray): The corresponding ground-truth validation dataset.\n",
    "        Returns:\n",
    "            accuracy (float): The accuracy of the network \n",
    "                              (= number of correct predictions/dataset size).\n",
    "        \"\"\"\n",
    "        num_corrects = 0\n",
    "        for i in range(len(X_val)):\n",
    "            pred_class = self.predict(X_val[i])\n",
    "            if pred_class == y_val[i]:\n",
    "                num_corrects += 1\n",
    "        return num_corrects / len(X_val)\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None, \n",
    "              batch_size=32, num_epochs=5, learning_rate=1e-3, print_frequency=20):\n",
    "        \"\"\"\n",
    "        Given a dataset and its ground-truth labels, evaluate the current accuracy of the network.\n",
    "        Args:\n",
    "            X_train (ndarray): The input training dataset.\n",
    "            y_train (ndarray): The corresponding ground-truth training dataset.\n",
    "            X_val (ndarray): The input validation dataset.\n",
    "            y_val (ndarray): The corresponding ground-truth validation dataset.\n",
    "            batch_size (int): The mini-batch size.\n",
    "            num_epochs (int): The number of training epochs i.e. iterations over the whole dataset.\n",
    "            learning_rate (float): The learning rate to scale the derivatives.\n",
    "            print_frequency (int): Frequency to print metrics (in epochs).\n",
    "        Returns:\n",
    "            losses (list): The list of training losses for each epoch.\n",
    "            accuracies (list): The list of validation accuracy values for each epoch.\n",
    "        \"\"\"\n",
    "        num_batches_per_epoch = len(X_train) // batch_size\n",
    "        do_validation = X_val is not None and y_val is not None\n",
    "        losses, accuracies = [], []\n",
    "        for i in range(num_epochs): # for each training epoch\n",
    "            epoch_loss = 0\n",
    "            for b in range(num_batches_per_epoch):  # for each batch composing the dataset\n",
    "                # Get batch:\n",
    "                batch_index_begin = b * batch_size\n",
    "                batch_index_end = batch_index_begin + batch_size\n",
    "                x = X_train[batch_index_begin: batch_index_end]\n",
    "                targets = y_train[batch_index_begin: batch_index_end]\n",
    "                # Optimize on batch:\n",
    "                predictions = y = self.forward(x)  # forward pass\n",
    "                L = self.loss_function(predictions, targets)  # loss computation\n",
    "                dL_dy = self.derivated_loss_function(predictions, targets)  # loss derivation\n",
    "                self.backward(dL_dy)  # back-propagation pass\n",
    "                self.optimize(learning_rate)  # optimization of the NN\n",
    "                epoch_loss += L\n",
    "\n",
    "            # Logging training loss and validation accuracy, to follow the training:\n",
    "            epoch_loss /= num_batches_per_epoch\n",
    "            losses.append(epoch_loss)\n",
    "            if do_validation:\n",
    "                accuracy = self.evaluate_accuracy(X_val, y_val)\n",
    "                accuracies.append(accuracy)\n",
    "            else:\n",
    "                accuracy = np.NaN\n",
    "            if i % print_frequency == 0 or i == (num_epochs - 1):\n",
    "                print(\"Epoch {:4d}: training loss = {:.6f} | val accuracy = {:.2f}%\".format(\n",
    "                    i, epoch_loss, accuracy * 100))\n",
    "        return losses, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** This class can also be found in [simple_network.py](simple_network.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our Network to Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using untrained perceptrons and layers on random inputs is however a bit dull. In this final section of the notebook, we instantiate and train our simple model to ***classify images of hand-written digits***. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we will use the the [MNIST dataset](http://yann.lecun.com/exdb/mnist) presented in the book[$^2$](#ref) (Yann LeCun and Corinna Cortes hold all copyrights for this dataset).\n",
    "\n",
    "Before implementing a solution, we should prepare the data, loading the MNIST images for training and testing methods. For simplicity, we will use the Python module [`mnist`](https://github.com/datapythonista/mnist) developed by [Marc Garcia](https://github.com/datapythonista), and already installed in this chapter's directory (see [`./mnist/`](mnist/__init__.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# !pip install matplotlib  # Uncomment and run if matplotlib is not installed yet.\n",
    "import matplotlib          # We use this package to visualize some data and results\n",
    "import matplotlib.pyplot as plt\n",
    "# import mnist\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mnist` module makes it simple to load the training and testing data (images and their labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.33, random_state=42)\n",
    "\n",
    "num_classes = 10    # classes are the digits from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number and size of the training/testing samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. we have 60,000 training samples and 10,000 testing one, with each sample an image of $28 \\times 28$ pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data, for instance using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAADtElEQVR4nO3dQVFjQRhG0XlTCEACDgIKiIQ4iAUcgAQkgAQcgIPgAAk4eGMgFWbDnzvMOcv04nsLbnUVm17Wdf0F9Pw+9wcAx4kTosQJUeKEKHFC1MUX5z/yX7nb7XZ07+3tbXRvyv39/djWw8PD2NYZLMd+dHNClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDgh6qvnGMYcDoexrennETabzdjWbrcb27q5uRnb+h+5OSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBCVeY7h8vLy3J/wbZ6ensa2rq+vx7b4Xm5OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTopZ1XU+dnzz8Vy3LMrq32WzGtrbb7djW4+Pj2NYPd/QP0s0JUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqItzf8A57Pf70b3n5+exrff397Gtq6ursa27u7uxrQo3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6KWdV1PnZ885O98fn6ObU0+W3A4HH7k1hksx350c0KUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCHq4twfcA4fHx+je5NPJLy8vIxt7ff7sa3/kZsTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqGVd11PnJw//VbvdbnRv8v2S29vbsa3X19exrR9uOfajmxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRXz3HAJyJmxOixAlR4oQocUKUOCFKnBD1B+qxRGt9hBaaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_idx = np.random.randint(0, X_test.shape[0])\n",
    "plt.imshow(digits.images[img_idx], cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[img_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our images match their ground-truth label, which is good news!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as our network only accepts column vectors, we need to _flatten_ the images into 1D vectors, i.e. vectors of shape `(1, 64)` (since $8 \\times 8 = 64$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(-1, 8 * 8), X_test.reshape(-1, 8 * 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let us have a look at our pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values between 0.0 and 16.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Pixel values between {} and {}\".format(X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are normal integer values for images with 8 bits per channel (`uint8`)... These values may be however too big for some of our operations. For instance, given a too big input value, our sigmoid may return `nan` (\"_not a number_\") because of the exponential function it uses, which may \"overflow\" with a large input value.\n",
    "\n",
    "It is thus customary to *normalize* the input data, i.e. to scale the values between 0 and 1 (or -1 and 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized pixel values between 0.0 and 0.06274509803921569\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train / 255., X_test / 255.\n",
    "print(\"Normalized pixel values between {} and {}\".format(X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to compute the loss, we need to ***one-hot*** the labels, e.g. converting the label `4` into `[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(num_classes)[y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to prepare the classifier itself. Let us use our `SimpleNetwork` class and instantiate a network with 2 hidden layers, taking a flattened image as input and returning a 10-value vector representing its belief the image belongs to each of the class (the highter the value,the stronger the belief): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier = SimpleNetwork(num_inputs=X_train.shape[1], \n",
    "                                 num_outputs=num_classes, hidden_layers_sizes=[64, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check how our network performs (computing its *loss* over the training set, and its *accuracy* over the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained : training loss = 4.189652 | val accuracy = 10.77%\n"
     ]
    }
   ],
   "source": [
    "predictions = mnist_classifier.forward(X_train)                         # forward pass\n",
    "loss_untrained = mnist_classifier.loss_function(predictions, y_train)   # loss computation\n",
    "\n",
    "accuracy_untrained = mnist_classifier.evaluate_accuracy(X_test, y_test)  # Accuracy\n",
    "print(\"Untrained : training loss = {:.6f} | val accuracy = {:.2f}%\".format(\n",
    "    loss_untrained, accuracy_untrained * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... This is a really poor performance... But as we know from the book, this is to be expected: we have yet to train our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching our Network to Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where things finally get interesting. As the whole training procedure is already explained and implemented, we simply have to launch it (note: the training takes minutes/hours):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: training loss = 3.393575 | val accuracy = 10.77%\n",
      "Epoch   20: training loss = 0.912496 | val accuracy = 15.99%\n",
      "Epoch   40: training loss = 0.903545 | val accuracy = 19.70%\n",
      "Epoch   60: training loss = 0.900067 | val accuracy = 20.88%\n",
      "Epoch   80: training loss = 0.896220 | val accuracy = 21.55%\n",
      "Epoch  100: training loss = 0.891809 | val accuracy = 22.05%\n",
      "Epoch  120: training loss = 0.886778 | val accuracy = 22.73%\n",
      "Epoch  140: training loss = 0.881184 | val accuracy = 24.41%\n",
      "Epoch  160: training loss = 0.874934 | val accuracy = 26.43%\n",
      "Epoch  180: training loss = 0.867669 | val accuracy = 28.45%\n",
      "Epoch  200: training loss = 0.858436 | val accuracy = 30.47%\n",
      "Epoch  220: training loss = 0.841755 | val accuracy = 32.32%\n",
      "Epoch  240: training loss = 0.828517 | val accuracy = 34.85%\n",
      "Epoch  260: training loss = 0.814971 | val accuracy = 38.72%\n",
      "Epoch  280: training loss = 0.800359 | val accuracy = 41.92%\n",
      "Epoch  300: training loss = 0.784805 | val accuracy = 44.61%\n",
      "Epoch  320: training loss = 0.768523 | val accuracy = 47.14%\n",
      "Epoch  340: training loss = 0.751579 | val accuracy = 49.66%\n",
      "Epoch  360: training loss = 0.734002 | val accuracy = 51.18%\n",
      "Epoch  380: training loss = 0.715873 | val accuracy = 53.54%\n",
      "Epoch  400: training loss = 0.697330 | val accuracy = 55.89%\n",
      "Epoch  420: training loss = 0.678556 | val accuracy = 58.08%\n",
      "Epoch  440: training loss = 0.659752 | val accuracy = 59.26%\n",
      "Epoch  460: training loss = 0.641117 | val accuracy = 60.27%\n",
      "Epoch  480: training loss = 0.622824 | val accuracy = 61.95%\n",
      "Epoch  499: training loss = 0.605895 | val accuracy = 63.47%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = mnist_classifier.train(X_train, y_train, X_test, y_test, \n",
    "                                            batch_size=30, num_epochs=500)\n",
    "# note: Reduce the batch size and/or number of epochs if your computer can't \n",
    "#       handle the computations / takes too long.\n",
    "#       Remember, numpy also uses the CPU, not GPUs as modern Deep Learning \n",
    "#       libraries do, hence the lack of computational performance here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost **95%** of accuracy! This is much better. Congratulations, we implemented and trained our first neural network classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the evolution of the loss and accuracy during the training, to better visualize the evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses, accuracies = [loss_untrained] + losses, [accuracy_untrained] + accuracies\n",
    "fig, ax_loss = plt.subplots()\n",
    "\n",
    "color = 'red'\n",
    "ax_loss.set_xlim([0, 510])\n",
    "ax_loss.set_xlabel('Epochs')\n",
    "ax_loss.set_ylabel('Training Loss', color=color)\n",
    "ax_loss.plot(losses, color=color)\n",
    "ax_loss.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax_acc = ax_loss.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'blue'\n",
    "ax_acc.set_xlim([0, 510])\n",
    "ax_acc.set_ylim([0, 1])\n",
    "ax_acc.set_ylabel('Val Accuracy', color=color)\n",
    "ax_acc.plot(accuracies, color=color)\n",
    "ax_acc.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our network *converged* quite fast, though the accuracy slowly kept increasing. It looks even like the accuracy could still go up a bit with some further training iterations... We leave it to our readers to check. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before concluding this notebook, let us verify how our network is now performing on our random test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 5; Correct class: 5\n"
     ]
    }
   ],
   "source": [
    "# We use `np.expand_dims(x, 0)` to simulate a batch (transforming the image shape\n",
    "# from (784,) to (1, 784)):\n",
    "predicted_class = mnist_classifier.predict(np.expand_dims(X_test[img_idx], 0))\n",
    "print('Predicted class: {}; Correct class: {}'.format(predicted_class, y_test[img_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Through this first notebook, we illustrated the main notions of Chapter 1, starting with the implementation of a single artificial neuron and ending up with a network compose of several thousand neurons, able to classify digits with a decent accuracy.\n",
    "\n",
    "Training this network was however a slow process. In the next chapter and related notebooks, we will finally get started with TensorFlow 2 and Keras, to easily scale up our use-cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref\"></a>\n",
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rosenblatt, F., 1958. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review 65, 386.\n",
    "2. LeCun, Y., Cortes, C., Burges, C., 2010. MNIST handwritten digit database. AT&T Labs [Online]. Available: http://yann.lecun.com/exdb/mnist 2, 18."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
