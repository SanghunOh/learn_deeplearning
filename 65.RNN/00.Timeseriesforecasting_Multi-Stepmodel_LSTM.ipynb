{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"00.Timeseriesforecasting_Multi-Stepmodel_LSTM.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb","timestamp":1593756846681}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2Pmxv2ioyCRw"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"b-2ShX25yNWf","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pa49bUnKyRgF"},"source":["# Time series forecasting"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"11Ilg92myRcw"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GU8C5qm_4vZb"},"source":["This tutorial is an introduction to time series forecasting using Recurrent Neural Networks (RNNs). This is covered in two parts: first, you will forecast a univariate time series, then you will forecast a multivariate time series."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7rZnJaGTWQw0","colab":{}},"source":["import tensorflow as tf\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TokBlnUhWFw9"},"source":["## The weather dataset\n","This tutorial uses a <a href=\"https://www.bgc-jena.mpg.de/wetter/\" class=\"external\">[weather time series dataset</a> recorded by the <a href=\"https://www.bgc-jena.mpg.de\" class=\"external\">Max Planck Institute for Biogeochemistry</a>.\n","\n","This dataset contains 14 different features such as air temperature, atmospheric pressure, and humidity. These were collected every 10 minutes, beginning in 2003. For efficiency, you will use only the data collected between 2009 and 2016. This section of the dataset was prepared by Fran√ßois Chollet for his book [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xyv_i85IWInT","colab":{}},"source":["zip_path = tf.keras.utils.get_file(\n","    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n","    fname='jena_climate_2009_2016.csv.zip',\n","    extract=True)\n","csv_path, _ = os.path.splitext(zip_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TX6uGeeeWIkG","colab":{}},"source":["df = pd.read_csv(csv_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ojHE-iCCWIhz","colab":{}},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ia-MPAHxbInX","colab":{}},"source":["TRAIN_SPLIT = 300000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EowWDtaNnH1y"},"source":["Setting seed to ensure reproducibility."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-x-GgENynHdx","colab":{}},"source":["tf.random.set_seed(13)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VlJYi3_HXcw8"},"source":["## Part 2: Forecast a multivariate time series"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hoxNZ2GM7DPm"},"source":["The original dataset contains fourteen features. For simplicity, this section considers only three of the original fourteen. The features used are air temperature, atmospheric pressure, and air density. \n","\n","To use more features, add their names to this list."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DphrB7bxSNDd","colab":{}},"source":["features_considered = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IfQUSiJfUpXJ","colab":{}},"source":["features = df[features_considered]\n","features.index = df['Date Time']\n","features.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qSfhTZi5r15R"},"source":["Let's have a look at how each of these features vary across time."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QdgC8zvGr21X","colab":{}},"source":["features.plot(subplots=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cqStgZ-O1b3_"},"source":["As mentioned, the first step will be to standardize the dataset using the mean and standard deviation of the training data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W7VuNIwfHRHx","colab":{}},"source":["TRAIN_SPLIT = 300000\n","dataset = features.values\n","data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n","data_std = dataset[:TRAIN_SPLIT].std(axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eJUeWDqploCt","colab":{}},"source":["dataset = (dataset-data_mean)/data_std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d-rVX4d3OF86","colab":{}},"source":["def multivariate_data(dataset, target, start_index, end_index, history_size,\n","                      target_size, step, single_step=False):\n","  data = []\n","  labels = []\n","\n","  start_index = start_index + history_size\n","  if end_index is None:\n","    end_index = len(dataset) - target_size\n","\n","  for i in range(start_index, end_index):\n","    indices = range(i-history_size, i, step)\n","    data.append(dataset[indices])\n","\n","    if single_step:\n","      labels.append(target[i+target_size])\n","    else:\n","      labels.append(target[i:i+target_size])\n","\n","  return np.array(data), np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2GnE087bJYSu"},"source":["### Multi-Step model\n","In a multi-step prediction model, given a past history, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predict a sequence of the future.\n","\n","For the multi-step model, the training data again consists of recordings over the past five days sampled every hour. However, here, the model needs to learn to predict the temperature for the next 12 hours. Since an obversation is taken every 10 minutes, the output is 72 predictions. For this task, the dataset needs to be prepared accordingly, thus the first step is just to create it again, but with a different target window."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kZCk9fqyJZqX","colab":{}},"source":["past_history = 720\n","future_target = 72\n","STEP = 6\n","\n","x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n","                                                 TRAIN_SPLIT, past_history,\n","                                                 future_target, STEP)\n","x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n","                                             TRAIN_SPLIT, None, past_history,\n","                                             future_target, STEP)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LImXPwAGRtWy"},"source":["Let's check out a sample data-point."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SpWDcBkQRwS-","colab":{}},"source":["print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n","print ('\\n Target temperature to predict : {}'.format(y_train_multi[0].shape))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cjR4PJArMOpA","colab":{}},"source":["BATCH_SIZE = 256\n","BUFFER_SIZE = 10000\n","\n","train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n","train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","\n","val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n","val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IZcg8FWpSG8K"},"source":["Plotting a sample data-point."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ksXKVbwBV7D3","colab":{}},"source":["def plot(history, true_future, prediction):\n","  plt.figure(figsize=(12, 6))\n","  num_in = create_time_steps(len(history))\n","  num_out = len(true_future)\n","\n","  plt.plot(num_in, np.array(history[:, 1]), label='History')\n","  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n","           label='True Future')\n","  if prediction.any():\n","    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n","             label='Predicted Future')\n","  plt.legend(loc='upper left')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LCQKetflZRMF"},"source":["In this plot and subsequent similar plots, the history and the future data are sampled every hour."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R6G8bacQR4w2","colab":{}},"source":["def create_time_steps(length):\n","  return list(range(-length, 0))\n","\n","for x, y in train_data_multi.take(1):\n","  plot(x[0], y[0], np.array([0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XOjz8DzZ4HFS"},"source":["Since the task here is a bit more complicated than the previous task, the model now consists of two LSTM layers. Finally, since 72 predictions are made, the dense layer outputs 72 predictions."]},{"cell_type":"code","metadata":{"id":"b9pIfRWqhBpE","colab_type":"code","colab":{}},"source":["x_train_multi.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_CIS_1znuUz","colab_type":"code","colab":{}},"source":["model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"byAl0NKSNBP6","colab":{}},"source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.LSTM(120, return_sequences=True, activation='relu', \n","                                          input_shape=x_train_multi.shape[-2:]))\n","                                          # stateful=True, batch_input_shape=(x_train_multi.shape[:-1])))\n","model.add(tf.keras.layers.Dropout(0.25))\n","model.add(tf.keras.layers.LSTM(60, activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.25))\n","model.add(tf.keras.layers.Dense(72))\n","\n","# model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n","model.compile(optimizer=tf.keras.optimizers.Nadam(), loss='mae', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VLnATwN_vWPt","colab_type":"text"},"source":["##GRU"]},{"cell_type":"code","metadata":{"id":"mHYQYaUDvS-o","colab_type":"code","colab":{}},"source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.GRU(120, return_sequences=True, \n","                                          input_shape=x_train_multi.shape[-2:]))\n","                                          # stateful=True, batch_input_shape=(x_train_multi.shape[:-1])))\n","model.add(tf.keras.layers.Dropout(0.25))\n","model.add(tf.keras.layers.GRU(60))\n","model.add(tf.keras.layers.Dropout(0.25))\n","model.add(tf.keras.layers.Dense(72))\n","\n","# model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n","model.compile(optimizer=tf.keras.optimizers.Nadam(), loss='mae', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTnBL3dfvoTy","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UvB7zBqVSMyl"},"source":["Let's see how the model predicts before it trains."]},{"cell_type":"code","metadata":{"id":"hzTp-hvhhNVw","colab_type":"code","colab":{}},"source":["model.input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"13_ZWvB9SRlZ","colab":{}},"source":["for x, y in val_data_multi.take(1):\n","  print(x.shape, y.shape)\n","  print (model.predict(x, batch_size=1).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7uwOhXo3Oems","colab":{}},"source":["EVALUATION_INTERVAL = 200\n","EPOCHS = 10\n","\n","hist_within = model.fit(train_data_multi, epochs=EPOCHS,\n","                                          steps_per_epoch=EVALUATION_INTERVAL,\n","                                          validation_data=val_data_multi,\n","                                          validation_steps=50, verbose=2)\n","\n","# model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n","# Epoch 10/10\n","# 200/200 - 33s 165ms/step - loss: 0.1960 - val_loss: 0.1888\n","\n","# units=120; model.compile(optimizer=tf.keras.optimizers.Nadam(), loss='mae', metrics=['accuracy'])\n","# Epoch 10/10\n","# 200/200 - 64s 318ms/step - loss: 0.1856 - accuracy: 0.1704 - val_loss: 0.1756 - val_accuracy: 0.1841\n","\n","# units=120; layers.Dropout(0.25)); model.compile(optimizer=tf.keras.optimizers.Nadam(), loss='mae', metrics=['accuracy'])\n","# Epoch 10/10\n","# 200/200 - 62s - loss: 0.1889 - accuracy: 0.1157 - val_loss: 0.1867 - val_accuracy: 0.1502\n","\n","# tf.keras.layers.GRU(60))\n","# Epoch 10/10\n","# 200/200 - 11s - loss: 0.2039 - accuracy: 0.1819 - val_loss: 0.1811 - val_accuracy: 0.2555"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LpOUxizTWMgL","colab_type":"text"},"source":["## without Dataset"]},{"cell_type":"code","metadata":{"id":"kgW1Qx5dYxLX","colab_type":"code","colab":{}},"source":["without_model = tf.keras.models.Sequential()\n","without_model.add(tf.keras.layers.LSTM(32,\n","                                          return_sequences=True,\n","                                          input_shape=x_train_multi.shape[-2:]))\n","without_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n","without_model.add(tf.keras.layers.Dense(72))\n","\n","without_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9NH7ncWWZcf","colab_type":"code","colab":{}},"source":["without_hist = without_model.fit(x_train_multi, y_train_multi, epochs=EPOCHS,\n","                                          steps_per_epoch=EVALUATION_INTERVAL,\n","                                          validation_data=(x_val_multi, y_val_multi),\n","                                          validation_steps=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MH0obqi8XvGu","colab_type":"code","colab":{}},"source":["hist = hist_within"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XtgyJn8JXoQN","colab_type":"code","colab":{}},"source":["def plot_train_history(history, title):\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  epochs = range(len(loss))\n","\n","  plt.figure()\n","\n","  plt.plot(epochs, loss, 'b', label='Training loss')\n","  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","  plt.title(title)\n","  plt.legend()\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UKfQoBjQ5l7U","colab":{}},"source":["plot_train_history(hist, 'Multi-Step Training and validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oDg94-yq4pas"},"source":["#### Predict a multi-step future\n","Let's now have a look at how well your network has learnt to predict the future."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dt22wq6fyIBU","colab":{}},"source":["for x, y in val_data_multi.take(3):\n","  plot(x[0], y[0], model.predict(x)[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pOzaIRYBhqwg"},"source":["## Next steps\n","This tutorial was a quick introduction to time series forecasting using an RNN. You may now try to predict the stock market and become a billionaire.\n","\n","In addition, you may also write a generator to yield data (instead of the uni/multivariate_data function), which would be more memory efficient. You may also check out this [time series windowing](https://www.tensorflow.org/guide/data#time_series_windowing) guide and use it in this tutorial.\n","\n","For further understanding, you may read Chapter 15 of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), 2nd Edition and Chapter 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)."]}]}