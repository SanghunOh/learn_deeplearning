{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/gilbutITbook/080228.git (모두의 딥러닝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 28, 28, 1)         865281    \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 212865    \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n",
      "epoch:0  d_loss:0.7053  g_loss:0.6912\n",
      "epoch:1  d_loss:0.4624  g_loss:0.3282\n",
      "epoch:2  d_loss:0.5685  g_loss:0.1024\n",
      "epoch:3  d_loss:0.6585  g_loss:0.0836\n",
      "epoch:4  d_loss:0.5767  g_loss:0.1650\n",
      "epoch:5  d_loss:0.5088  g_loss:0.4210\n",
      "epoch:6  d_loss:0.4876  g_loss:0.6973\n",
      "epoch:7  d_loss:0.5091  g_loss:0.8702\n",
      "epoch:8  d_loss:0.4966  g_loss:0.8973\n",
      "epoch:9  d_loss:0.4861  g_loss:0.8726\n",
      "epoch:10  d_loss:0.4173  g_loss:0.7870\n",
      "epoch:11  d_loss:0.4381  g_loss:0.8116\n",
      "epoch:12  d_loss:0.4799  g_loss:0.8681\n",
      "epoch:13  d_loss:0.4736  g_loss:0.9209\n",
      "epoch:14  d_loss:0.5728  g_loss:0.9727\n",
      "epoch:15  d_loss:0.4733  g_loss:1.0472\n",
      "epoch:16  d_loss:0.4024  g_loss:1.0547\n",
      "epoch:17  d_loss:0.6229  g_loss:0.7730\n",
      "epoch:18  d_loss:0.5678  g_loss:0.6428\n",
      "epoch:19  d_loss:0.4588  g_loss:0.7205\n",
      "epoch:20  d_loss:0.4227  g_loss:0.8017\n",
      "epoch:21  d_loss:0.5006  g_loss:0.8394\n",
      "epoch:22  d_loss:0.5128  g_loss:0.6692\n",
      "epoch:23  d_loss:0.4540  g_loss:0.6200\n",
      "epoch:24  d_loss:0.4481  g_loss:0.6710\n",
      "epoch:25  d_loss:0.4664  g_loss:0.7126\n",
      "epoch:26  d_loss:0.5107  g_loss:0.7382\n",
      "epoch:27  d_loss:0.4701  g_loss:0.6049\n",
      "epoch:28  d_loss:0.4996  g_loss:0.5215\n",
      "epoch:29  d_loss:0.5156  g_loss:0.5576\n",
      "epoch:30  d_loss:0.4472  g_loss:0.6156\n",
      "epoch:31  d_loss:0.4777  g_loss:0.6919\n",
      "epoch:32  d_loss:0.4383  g_loss:0.5767\n",
      "epoch:33  d_loss:0.4307  g_loss:0.6093\n",
      "epoch:34  d_loss:0.3250  g_loss:0.7332\n",
      "epoch:35  d_loss:0.3650  g_loss:0.8835\n",
      "epoch:36  d_loss:0.4343  g_loss:0.5756\n",
      "epoch:37  d_loss:0.3549  g_loss:0.7309\n",
      "epoch:38  d_loss:0.3310  g_loss:0.9196\n",
      "epoch:39  d_loss:0.2260  g_loss:1.2252\n",
      "epoch:40  d_loss:0.3132  g_loss:1.2334\n",
      "epoch:41  d_loss:0.4138  g_loss:0.8897\n",
      "epoch:42  d_loss:0.3744  g_loss:0.7448\n",
      "epoch:43  d_loss:0.2157  g_loss:1.1655\n",
      "epoch:44  d_loss:0.2061  g_loss:1.5023\n",
      "epoch:45  d_loss:0.1516  g_loss:2.0839\n",
      "epoch:46  d_loss:0.3359  g_loss:1.6827\n",
      "epoch:47  d_loss:0.2496  g_loss:1.0884\n",
      "epoch:48  d_loss:0.2980  g_loss:1.2038\n",
      "epoch:49  d_loss:0.3114  g_loss:1.4908\n",
      "epoch:50  d_loss:0.3018  g_loss:1.7507\n",
      "epoch:51  d_loss:0.3920  g_loss:2.1809\n",
      "epoch:52  d_loss:0.2527  g_loss:2.1558\n",
      "epoch:53  d_loss:0.1499  g_loss:1.6072\n",
      "epoch:54  d_loss:0.0921  g_loss:2.1662\n",
      "epoch:55  d_loss:0.1069  g_loss:2.9345\n",
      "epoch:56  d_loss:0.1179  g_loss:2.1552\n",
      "epoch:57  d_loss:0.2944  g_loss:2.7602\n",
      "epoch:58  d_loss:0.2916  g_loss:3.4916\n",
      "epoch:59  d_loss:0.3888  g_loss:2.8026\n",
      "epoch:60  d_loss:0.6346  g_loss:2.2368\n",
      "epoch:61  d_loss:0.5007  g_loss:2.7556\n",
      "epoch:62  d_loss:0.7278  g_loss:2.3246\n",
      "epoch:63  d_loss:0.5783  g_loss:2.3535\n",
      "epoch:64  d_loss:0.4400  g_loss:3.0349\n",
      "epoch:65  d_loss:0.6803  g_loss:3.1025\n",
      "epoch:66  d_loss:0.3899  g_loss:2.8093\n",
      "epoch:67  d_loss:0.2877  g_loss:3.1032\n",
      "epoch:68  d_loss:0.2034  g_loss:4.0828\n",
      "epoch:69  d_loss:0.5611  g_loss:2.6659\n",
      "epoch:70  d_loss:0.7679  g_loss:1.5297\n",
      "epoch:71  d_loss:0.4364  g_loss:2.2095\n",
      "epoch:72  d_loss:0.6918  g_loss:2.1721\n",
      "epoch:73  d_loss:0.5692  g_loss:1.8635\n",
      "epoch:74  d_loss:1.0018  g_loss:0.8661\n",
      "epoch:75  d_loss:0.9385  g_loss:0.9964\n",
      "epoch:76  d_loss:0.7070  g_loss:1.5482\n",
      "epoch:77  d_loss:0.6454  g_loss:2.3788\n",
      "epoch:78  d_loss:0.5032  g_loss:2.4250\n",
      "epoch:79  d_loss:0.3228  g_loss:2.4680\n",
      "epoch:80  d_loss:0.2462  g_loss:2.5170\n",
      "epoch:81  d_loss:0.1986  g_loss:3.0192\n",
      "epoch:82  d_loss:0.1926  g_loss:3.3230\n",
      "epoch:83  d_loss:0.1144  g_loss:4.6522\n",
      "epoch:84  d_loss:0.2868  g_loss:4.8210\n",
      "epoch:85  d_loss:0.6260  g_loss:3.7284\n",
      "epoch:86  d_loss:0.5928  g_loss:3.7236\n",
      "epoch:87  d_loss:0.6542  g_loss:4.4159\n",
      "epoch:88  d_loss:0.9348  g_loss:3.6296\n",
      "epoch:89  d_loss:1.1079  g_loss:3.2144\n",
      "epoch:90  d_loss:0.8365  g_loss:3.2689\n",
      "epoch:91  d_loss:0.8854  g_loss:3.4968\n",
      "epoch:92  d_loss:1.0676  g_loss:2.4129\n",
      "epoch:93  d_loss:1.0333  g_loss:1.9853\n",
      "epoch:94  d_loss:0.9138  g_loss:1.5902\n",
      "epoch:95  d_loss:0.7226  g_loss:1.7401\n",
      "epoch:96  d_loss:0.6040  g_loss:1.7120\n",
      "epoch:97  d_loss:0.5455  g_loss:2.0113\n",
      "epoch:98  d_loss:0.4817  g_loss:1.8588\n",
      "epoch:99  d_loss:0.6485  g_loss:1.7012\n",
      "epoch:100  d_loss:0.5872  g_loss:1.5895\n",
      "epoch:101  d_loss:0.4198  g_loss:1.3890\n",
      "epoch:102  d_loss:0.4281  g_loss:1.3241\n",
      "epoch:103  d_loss:0.5205  g_loss:1.2004\n",
      "epoch:104  d_loss:0.3660  g_loss:1.3322\n",
      "epoch:105  d_loss:0.5166  g_loss:1.1684\n",
      "epoch:106  d_loss:0.4954  g_loss:1.2051\n",
      "epoch:107  d_loss:0.4111  g_loss:1.2866\n",
      "epoch:108  d_loss:0.4981  g_loss:1.0013\n",
      "epoch:109  d_loss:0.3808  g_loss:1.1860\n",
      "epoch:110  d_loss:0.4306  g_loss:1.4650\n",
      "epoch:111  d_loss:0.5097  g_loss:1.1251\n",
      "epoch:112  d_loss:0.4872  g_loss:1.2406\n",
      "epoch:113  d_loss:0.5342  g_loss:1.0743\n",
      "epoch:114  d_loss:0.6471  g_loss:1.0007\n",
      "epoch:115  d_loss:0.5507  g_loss:0.8336\n",
      "epoch:116  d_loss:0.5623  g_loss:0.9264\n",
      "epoch:117  d_loss:0.5734  g_loss:0.8402\n",
      "epoch:118  d_loss:0.6681  g_loss:0.9999\n",
      "epoch:119  d_loss:0.4906  g_loss:1.1915\n",
      "epoch:120  d_loss:0.6436  g_loss:1.0673\n",
      "epoch:121  d_loss:0.7075  g_loss:0.9544\n",
      "epoch:122  d_loss:0.8241  g_loss:0.8904\n",
      "epoch:123  d_loss:0.7502  g_loss:0.8019\n",
      "epoch:124  d_loss:0.6584  g_loss:0.7796\n",
      "epoch:125  d_loss:0.7437  g_loss:0.9488\n",
      "epoch:126  d_loss:0.6295  g_loss:0.9701\n",
      "epoch:127  d_loss:0.5081  g_loss:1.2160\n",
      "epoch:128  d_loss:0.5805  g_loss:1.2808\n",
      "epoch:129  d_loss:0.4742  g_loss:1.5791\n",
      "epoch:130  d_loss:0.4846  g_loss:1.4327\n",
      "epoch:131  d_loss:0.4881  g_loss:1.4434\n",
      "epoch:132  d_loss:0.4653  g_loss:1.4534\n",
      "epoch:133  d_loss:0.4070  g_loss:1.6617\n",
      "epoch:134  d_loss:0.3471  g_loss:1.7795\n",
      "epoch:135  d_loss:0.2736  g_loss:2.3321\n",
      "epoch:136  d_loss:0.4254  g_loss:2.0676\n",
      "epoch:137  d_loss:0.3003  g_loss:2.2823\n",
      "epoch:138  d_loss:0.3407  g_loss:1.9937\n",
      "epoch:139  d_loss:0.4125  g_loss:2.0000\n",
      "epoch:140  d_loss:0.3210  g_loss:2.6526\n",
      "epoch:141  d_loss:0.5059  g_loss:2.8222\n",
      "epoch:142  d_loss:0.5439  g_loss:2.2380\n",
      "epoch:143  d_loss:0.4965  g_loss:1.8555\n",
      "epoch:144  d_loss:0.5256  g_loss:2.2422\n",
      "epoch:145  d_loss:0.5528  g_loss:2.3212\n",
      "epoch:146  d_loss:0.5884  g_loss:2.9186\n",
      "epoch:147  d_loss:1.0808  g_loss:2.5083\n",
      "epoch:148  d_loss:0.8045  g_loss:1.9455\n",
      "epoch:149  d_loss:0.8160  g_loss:1.6392\n",
      "epoch:150  d_loss:0.8341  g_loss:1.7150\n",
      "epoch:151  d_loss:0.8105  g_loss:1.7270\n",
      "epoch:152  d_loss:0.8337  g_loss:1.8658\n",
      "epoch:153  d_loss:0.6815  g_loss:1.4432\n",
      "epoch:154  d_loss:0.6679  g_loss:1.3208\n",
      "epoch:155  d_loss:0.6792  g_loss:1.1680\n",
      "epoch:156  d_loss:0.6680  g_loss:1.2122\n",
      "epoch:157  d_loss:0.5374  g_loss:1.3832\n",
      "epoch:158  d_loss:0.5130  g_loss:1.3950\n",
      "epoch:159  d_loss:0.5111  g_loss:1.3883\n",
      "epoch:160  d_loss:0.5244  g_loss:1.5313\n",
      "epoch:161  d_loss:0.6420  g_loss:1.5776\n",
      "epoch:162  d_loss:0.5063  g_loss:1.6835\n",
      "epoch:163  d_loss:0.4529  g_loss:1.6257\n",
      "epoch:164  d_loss:0.4238  g_loss:1.4884\n",
      "epoch:165  d_loss:0.4050  g_loss:1.5442\n",
      "epoch:166  d_loss:0.4224  g_loss:1.5465\n",
      "epoch:167  d_loss:0.4351  g_loss:1.6275\n",
      "epoch:168  d_loss:0.4011  g_loss:1.5310\n",
      "epoch:169  d_loss:0.4215  g_loss:1.6049\n",
      "epoch:170  d_loss:0.3542  g_loss:1.6144\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#이미지가 저장될 폴더가 없다면 만듭니다.\n",
    "import os\n",
    "if not os.path.exists(\"./model_gan_images\"):\n",
    "    os.makedirs(\"./model_gan_images\")\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#생성자 모델을 만듭니다.\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "\n",
    "#판별자 모델을 만듭니다.\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "\n",
    "#생성자와 판별자 모델을 연결시키는 gan 모델을 만듭니다.\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()\n",
    "\n",
    "#신경망을 실행시키는 함수를 만듭니다.\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "\n",
    "  # MNIST 데이터 불러오기\n",
    "\n",
    "  (X_train, _), (_, _) = mnist.load_data()  # 앞서 불러온 적 있는 MNIST를 다시 이용합니다. 단, 테스트과정은 필요없고 이미지만 사용할 것이기 때문에 X_train만 불러왔습니다.\n",
    "  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_train = (X_train - 127.5) / 127.5  # 픽셀값은 0에서 255사이의 값입니다. 이전에 255로 나누어 줄때는 이를 0~1사이의 값으로 바꾸었던 것인데, 여기서는 127.5를 빼준 뒤 127.5로 나누어 줌으로 인해 -1에서 1사이의 값으로 바뀌게 됩니다.\n",
    "  #X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "  true = np.ones((batch_size, 1))\n",
    "  fake = np.zeros((batch_size, 1))\n",
    "\n",
    "  for i in range(epoch):\n",
    "          # 실제 데이터를 판별자에 입력하는 부분입니다.\n",
    "          idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "          imgs = X_train[idx]\n",
    "          d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "          #가상 이미지를 판별자에 입력하는 부분입니다.\n",
    "          noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "          gen_imgs = generator.predict(noise)\n",
    "          d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "          #판별자와 생성자의 오차를 계산합니다.\n",
    "          d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "          g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "          print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "        # 이부분은 중간 과정을 이미지로 저장해 주는 부분입니다. 본 장의 주요 내용과 관련이 없어\n",
    "        # 소스코드만 첨부합니다. 만들어진 이미지들은 gan_images 폴더에 저장됩니다.\n",
    "          if i % saving_interval == 0:\n",
    "              #r, c = 5, 5\n",
    "              noise = np.random.normal(0, 1, (25, 100))\n",
    "              gen_imgs = generator.predict(noise)\n",
    "\n",
    "              # Rescale images 0 - 1\n",
    "              gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "              fig, axs = plt.subplots(5, 5)\n",
    "              count = 0\n",
    "              for j in range(5):\n",
    "                  for k in range(5):\n",
    "                      axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                      axs[j, k].axis('off')\n",
    "                      count += 1\n",
    "              fig.savefig(\"model_gan_images/gan_mnist_%d.png\" % i)\n",
    "\n",
    "gan_train(4001, 32, 200)  #4000번 반복되고(+1을 해 주는 것에 주의), 배치 사이즈는 32,  200번 마다 결과가 저장되게 하였습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
