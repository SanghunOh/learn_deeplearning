{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border: 1px solid #e7692c; border-left: 15px solid #e7692c; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c\">Tip.</strong> <a style=\"color: #000000;\" href=\"https://nbviewer.jupyter.org/github/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/Chapter09/ch9_nb3_train_model.ipynb\" title=\"View with Jupyter Online\">Click here to view this notebook on <code>nbviewer.jupyter.org</code></a>. \n",
    "    <br/>These notebooks are better read there, as Github default viewer ignores some of the formatting and interactive content.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:38:46.581850Z",
     "start_time": "2019-04-12T22:38:46.573807Z"
    }
   },
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "    <tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #363636; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #e7692c;\">Hands-on</span> Computer Vision with TensorFlow 2</span><br/>by <em>Eliot Andres</em> & <em>Benjamin Planche</em> (Packt Pub.)</strong><br/><br/>\n",
    "        <strong>> Chapter 9: Performance and running on mobile</strong><br/>\n",
    "    </p>\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #e7692c;\">Notebook 3:</small><br/>Training a model and converting it for mobile devices</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #363636; text-align:justify; padding: 0 10px;\">\n",
    "    In this chapter, we covered how to convert and run a model on mobile.\n",
    "<br/><br/>\n",
    "    This notebooks trains a model to recognize face expressions and converts it to CoreML, TFLite and TensorFlow.js\n",
    "</p>\n",
    "<br/>\n",
    "\n",
    "<p style=\"border-left: 15px solid #363636; text-align:justify; padding: 0 10px;\">\n",
    "    <strong> Requirements </strong>\n",
    "<br/><br/>\n",
    "    To run this notebook, you need to download the <a href=\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\">FER dataset</a> and extract it. When done, change the `BASE_PATH` variable to point to the dataset folder.\n",
    "</p>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #e7692c; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c;\">Tip.</strong> The notebooks shared on this git repository illustrate some notions from the book \"<em><strong>Hands-on Computer Vision with TensorFlow 2</strong></em>\" written by Eliot Andres and Benjamin Planche, published by Packt. If you enjoyed the insights shared here, <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Learn more about the book!\"><strong>please consider acquiring the book!</strong></a>\n",
    "<br/><br/>\n",
    "The book provides further guidance for those eager to learn about computer vision and to harness the power of TensorFlow 2 and Keras to build efficient recognition systems for object detection, segmentation, video processing, smartphone applications, and more.</p>\n",
    "        </td>\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; width: 280px;\">\n",
    "    <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Learn more about the book!\" target=\"_blank\">\n",
    "        <img src=\"../banner_images/book_cover.png\" width=280>\n",
    "    </a>\n",
    "    <p style=\"background: #e7692c; color:#ffffff; padding: 10px; text-align:justify;\"><strong>Leverage deep learning to create powerful image processing apps with TensorFlow 2 and Keras. <br/></strong>Get the book for more insights!</p>\n",
    "    <ul style=\"height: 32px; white-space: nowrap; text-align: center; margin: 0px; padding: 0px; padding-top: 10px;\">\n",
    "    <li style=\"display: block;height: 100%;float: left;vertical-align: middle;margin: 0 25px 10px;padding: 0px;\">\n",
    "        <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Get the book on Amazon (paperback or Kindle version)!\" target=\"_blank\">\n",
    "        <img style=\"vertical-align: middle; max-width: 72px; max-height: 32px;\" src=\"../banner_images/logo_amazon.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    <li style=\"display: inline-block;height: 100%;vertical-align: middle;float: right;margin: -5px 25px 10px;padding: 0px;\">\n",
    "        <a href=\"https://www.packtpub.com/application-development/hands-computer-vision-tensorflow-2\" title=\"Get your Packt book (paperback, PDF, ePUB, or MOBI version)!\" target=\"_blank\">\n",
    "        <img style=\"vertical-align: middle; max-width: 72px; max-height: 32px;\" src=\"../banner_images/logo_packt.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    </ul>\n",
    "        </td>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:32:47.307854Z",
     "start_time": "2019-05-26T14:32:46.208824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants and parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:32:47.631723Z",
     "start_time": "2019-05-26T14:32:47.624298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download data here: https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n",
    "DATASET_PATH = '../data/fer2013/fer2013.csv'\n",
    "\n",
    "IMAGE_SIZE = (48, 48)\n",
    "INPUT_SHAPE = IMAGE_SIZE + (1,)\n",
    "EMOTIONS = [\"angry\", \"disgust\", \"scared\",\n",
    "            \"happy\", \"sad\", \"surprised\", \"neutral\"]\n",
    "CALLBACK_PATIENCE = 50\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "VALIDATION_SPLIT = .2\n",
    "NUM_CLASSES = len(EMOTIONS)\n",
    "L2_REGULARIZATION = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:32:51.437882Z",
     "start_time": "2019-05-26T14:32:49.688747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 48, 48, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 24, 24, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 24, 24, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 24, 24, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 12, 12, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 12, 12, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 12, 12, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 12, 12, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 6, 6, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 6, 6, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 6, 6, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 6, 6, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 3, 3, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 3, 3, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 3,235,463\n",
      "Trainable params: 3,213,575\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=INPUT_SHAPE)\n",
    "model = MobileNet(input_tensor=input_tensor, alpha=1.0,\n",
    "                    include_top=False, weights=None)\n",
    "\n",
    "output = tf.keras.layers.Reshape((1024,))(model.output)\n",
    "output = tf.keras.layers.Dense(7, activation='softmax')(output)\n",
    "model = tf.keras.Model(model.input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:33:26.174937Z",
     "start_time": "2019-05-26T14:33:08.169194Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_fer2013():\n",
    "    data = pd.read_csv(DATASET_PATH)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'), IMAGE_SIZE)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).values\n",
    "    return faces, emotions\n",
    "\n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    x = x - 0.5\n",
    "    x = x * 2.0\n",
    "    return x\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# loading dataset\n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:29:36.416888Z",
     "start_time": "2019-05-26T14:11:17.714535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/free/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "897/897 [==============================] - 161s 178ms/step - loss: 1.8797 - accuracy: 0.2474 - val_loss: 1.8215 - val_accuracy: 0.2598\n",
      "Epoch 2/50\n",
      "897/897 [==============================] - 163s 181ms/step - loss: 1.8030 - accuracy: 0.2805 - val_loss: 2.1626 - val_accuracy: 0.2607\n",
      "Epoch 3/50\n",
      "897/897 [==============================] - 164s 183ms/step - loss: 1.7437 - accuracy: 0.3145 - val_loss: 1.6619 - val_accuracy: 0.3583\n",
      "Epoch 4/50\n",
      "897/897 [==============================] - 168s 187ms/step - loss: 1.7047 - accuracy: 0.3368 - val_loss: 2.0152 - val_accuracy: 0.2763\n",
      "Epoch 5/50\n",
      "897/897 [==============================] - 161s 180ms/step - loss: 1.6771 - accuracy: 0.3494 - val_loss: 1.8689 - val_accuracy: 0.2711\n",
      "Epoch 6/50\n",
      "897/897 [==============================] - 159s 177ms/step - loss: 1.6520 - accuracy: 0.3553 - val_loss: 1.5316 - val_accuracy: 0.4030\n",
      "Epoch 7/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.5612 - accuracy: 0.3974 - val_loss: 1.4791 - val_accuracy: 0.4242\n",
      "Epoch 8/50\n",
      "897/897 [==============================] - 154s 171ms/step - loss: 1.5274 - accuracy: 0.4122 - val_loss: 1.4788 - val_accuracy: 0.4352\n",
      "Epoch 9/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.4883 - accuracy: 0.4270 - val_loss: 1.4368 - val_accuracy: 0.4535\n",
      "Epoch 10/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.4499 - accuracy: 0.4462 - val_loss: 1.6698 - val_accuracy: 0.3149\n",
      "Epoch 11/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.4435 - accuracy: 0.4477 - val_loss: 1.4630 - val_accuracy: 0.4359\n",
      "Epoch 12/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.3672 - accuracy: 0.4776 - val_loss: 1.3397 - val_accuracy: 0.4870\n",
      "Epoch 13/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.3387 - accuracy: 0.4925 - val_loss: 1.3060 - val_accuracy: 0.5039\n",
      "Epoch 14/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.3489 - accuracy: 0.4870 - val_loss: 1.2744 - val_accuracy: 0.5071\n",
      "Epoch 15/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.3029 - accuracy: 0.5075 - val_loss: 1.3330 - val_accuracy: 0.4843\n",
      "Epoch 16/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.2673 - accuracy: 0.5226 - val_loss: 1.3119 - val_accuracy: 0.5040\n",
      "Epoch 17/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.2710 - accuracy: 0.5227 - val_loss: 1.1965 - val_accuracy: 0.5508\n",
      "Epoch 18/50\n",
      "897/897 [==============================] - 154s 172ms/step - loss: 1.2427 - accuracy: 0.5331 - val_loss: 1.2257 - val_accuracy: 0.5284\n",
      "Epoch 19/50\n",
      "897/897 [==============================] - 156s 174ms/step - loss: 1.2004 - accuracy: 0.5483 - val_loss: 1.1513 - val_accuracy: 0.5567\n",
      "Epoch 20/50\n",
      "897/897 [==============================] - 158s 176ms/step - loss: 1.1872 - accuracy: 0.5535 - val_loss: 1.2667 - val_accuracy: 0.5199\n",
      "Epoch 21/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.1754 - accuracy: 0.5546 - val_loss: 1.1287 - val_accuracy: 0.5741\n",
      "Epoch 22/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 1.1480 - accuracy: 0.5677 - val_loss: 1.0997 - val_accuracy: 0.5846\n",
      "Epoch 23/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.1336 - accuracy: 0.5723 - val_loss: 1.1373 - val_accuracy: 0.5755\n",
      "Epoch 24/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.1209 - accuracy: 0.5803 - val_loss: 1.1944 - val_accuracy: 0.5539\n",
      "Epoch 25/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.1159 - accuracy: 0.5807 - val_loss: 1.1435 - val_accuracy: 0.5652\n",
      "Epoch 26/50\n",
      "897/897 [==============================] - 156s 174ms/step - loss: 1.1019 - accuracy: 0.5884 - val_loss: 2.0329 - val_accuracy: 0.2785\n",
      "Epoch 27/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.1106 - accuracy: 0.5816 - val_loss: 1.0863 - val_accuracy: 0.5850\n",
      "Epoch 28/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 1.0685 - accuracy: 0.5980 - val_loss: 1.1652 - val_accuracy: 0.5666\n",
      "Epoch 29/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.0721 - accuracy: 0.5984 - val_loss: 1.0668 - val_accuracy: 0.5997\n",
      "Epoch 30/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 1.0508 - accuracy: 0.6045 - val_loss: 1.0637 - val_accuracy: 0.6004\n",
      "Epoch 31/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.0401 - accuracy: 0.6101 - val_loss: 1.0867 - val_accuracy: 0.5938\n",
      "Epoch 32/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.0427 - accuracy: 0.6089 - val_loss: 1.0554 - val_accuracy: 0.6039\n",
      "Epoch 33/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 1.0211 - accuracy: 0.6186 - val_loss: 1.0718 - val_accuracy: 0.5985\n",
      "Epoch 34/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.0212 - accuracy: 0.6212 - val_loss: 1.0390 - val_accuracy: 0.6186\n",
      "Epoch 35/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 1.0110 - accuracy: 0.6250 - val_loss: 1.0651 - val_accuracy: 0.6038\n",
      "Epoch 36/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 0.9987 - accuracy: 0.6276 - val_loss: 1.0898 - val_accuracy: 0.5846\n",
      "Epoch 37/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 0.9939 - accuracy: 0.6284 - val_loss: 1.0407 - val_accuracy: 0.6116\n",
      "Epoch 38/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 0.9790 - accuracy: 0.6339 - val_loss: 1.0962 - val_accuracy: 0.5879\n",
      "Epoch 39/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 0.9849 - accuracy: 0.6358 - val_loss: 1.0522 - val_accuracy: 0.6113\n",
      "Epoch 40/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 0.9694 - accuracy: 0.6406 - val_loss: 1.1213 - val_accuracy: 0.5790\n",
      "Epoch 41/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 0.9600 - accuracy: 0.6435 - val_loss: 1.0443 - val_accuracy: 0.6099\n",
      "Epoch 42/50\n",
      "897/897 [==============================] - 156s 174ms/step - loss: 0.9522 - accuracy: 0.6443 - val_loss: 1.0197 - val_accuracy: 0.6225\n",
      "Epoch 43/50\n",
      "897/897 [==============================] - 156s 174ms/step - loss: 0.9465 - accuracy: 0.6453 - val_loss: 1.0568 - val_accuracy: 0.6050\n",
      "Epoch 44/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 0.9409 - accuracy: 0.6475 - val_loss: 1.0128 - val_accuracy: 0.6236\n",
      "Epoch 45/50\n",
      "897/897 [==============================] - 156s 174ms/step - loss: 0.9324 - accuracy: 0.6487 - val_loss: 1.0219 - val_accuracy: 0.6216\n",
      "Epoch 46/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 0.9224 - accuracy: 0.6559 - val_loss: 1.0172 - val_accuracy: 0.6257\n",
      "Epoch 47/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 0.9353 - accuracy: 0.6514 - val_loss: 1.0143 - val_accuracy: 0.6280\n",
      "Epoch 48/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 0.9096 - accuracy: 0.6627 - val_loss: 1.0047 - val_accuracy: 0.6314\n",
      "Epoch 49/50\n",
      "897/897 [==============================] - 157s 174ms/step - loss: 0.9052 - accuracy: 0.6645 - val_loss: 1.0447 - val_accuracy: 0.6038\n",
      "Epoch 50/50\n",
      "897/897 [==============================] - 157s 175ms/step - loss: 0.9030 - accuracy: 0.6625 - val_loss: 1.0519 - val_accuracy: 0.6126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f9c1905f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularization = tf.keras.regularizers.l2(L2_REGULARIZATION)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=CALLBACK_PATIENCE)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    'val_loss', factor=0.1, patience=int(CALLBACK_PATIENCE/4), verbose=1)\n",
    "tensorboard = TensorBoard('./logs')\n",
    "callbacks = [early_stop, reduce_lr, tensorboard]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.2)\n",
    "\n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain, BATCH_SIZE),\n",
    "                    steps_per_epoch=len(xtrain) / BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS, verbose=1, callbacks=callbacks,\n",
    "                    validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CoreML for IOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tfcoreml\n",
      "  Downloading tfcoreml-2.0-py3-none-any.whl (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 1.5 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.2 in /home/free/.local/lib/python3.6/site-packages (from tfcoreml) (1.19.5)\n",
      "Collecting tensorflow<=1.14,>=1.5.0\n",
      "  Downloading tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2 MB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.1.0 in /home/free/.local/lib/python3.6/site-packages (from tfcoreml) (3.17.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/free/.local/lib/python3.6/site-packages (from tfcoreml) (1.15.0)\n",
      "Collecting coremltools>=0.8\n",
      "  Downloading coremltools-4.1-cp36-none-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs in /home/free/.local/lib/python3.6/site-packages (from coremltools>=0.8->tfcoreml) (21.2.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.8-py3-none-any.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/free/.local/lib/python3.6/site-packages (from coremltools>=0.8->tfcoreml) (1.5.4)\n",
      "Requirement already satisfied: tqdm in /home/free/.local/lib/python3.6/site-packages (from coremltools>=0.8->tfcoreml) (4.61.0)\n",
      "Requirement already satisfied: packaging in /home/free/.local/lib/python3.6/site-packages (from coremltools>=0.8->tfcoreml) (20.9)\n",
      "Collecting attr\n",
      "  Downloading attr-0.3.1.tar.gz (1.7 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.12.1)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.12.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.4.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001b[K     |████████████████████████████████| 488 kB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.1.2)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 2.5 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<=1.14,>=1.5.0->tfcoreml) (1.34.1)\n",
      "Requirement already satisfied: h5py in /home/free/.local/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/free/.local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (57.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/free/.local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/free/.local/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/free/.local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (4.3.0)\n",
      "Requirement already satisfied: dataclasses in /home/free/.local/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (0.8)\n",
      "Requirement already satisfied: cached-property in /home/free/.local/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.6->tensorflow<=1.14,>=1.5.0->tfcoreml) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/free/.local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/free/.local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow<=1.14,>=1.5.0->tfcoreml) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/free/.local/lib/python3.6/site-packages (from packaging->coremltools>=0.8->tfcoreml) (2.4.7)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[K     |████████████████████████████████| 532 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: attr\n",
      "  Building wheel for attr (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for attr: filename=attr-0.3.1-py3-none-any.whl size=2457 sha256=87f06879244f08cbe1f4985f1d4806fca8f50a0b8cbd9e8aa607d0da6cbe8948\n",
      "  Stored in directory: /home/free/.cache/pip/wheels/da/51/18/7b8531558401f15a9eebc9aef5a66c59fb7b1d4b84a458ecdf\n",
      "Successfully built attr\n",
      "Installing collected packages: mpmath, tensorflow-estimator, tensorboard, sympy, keras-applications, attr, astor, tensorflow, coremltools, tfcoreml\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "Successfully installed astor-0.8.1 attr-0.3.1 coremltools-4.1 keras-applications-1.0.8 mpmath-1.2.1 sympy-1.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 tfcoreml-2.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install tfcoreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:34:41.620005Z",
     "start_time": "2019-05-26T14:34:27.856889Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tfcoreml as tf_converter\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "input_saved_model_dir = \"./saved_model\"\n",
    "\n",
    "# previous version\n",
    "# tf.keras.experimental.export_saved_model(\n",
    "#     model, saved_model_path=input_saved_model_dir, serving_only=False)\n",
    "tf.saved_model.save(\n",
    "    model, input_saved_model_dir, signatures=None, options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model with tensorflow v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Attempting to add a duplicate function with name: __inference_conv_pw_4_layer_call_and_return_conditional_losses_165349 where the previous and current definitions differ. Previous definition: signature {\n  name: \"__inference_conv_pw_4_layer_call_and_return_conditional_losses_165349\"\n  input_arg {\n    name: \"inputs\"\n    type: DT_FLOAT\n  }\n  input_arg {\n    name: \"conv2d_readvariableop_resource\"\n    type: DT_RESOURCE\n  }\n  output_arg {\n    name: \"identity\"\n    type: DT_FLOAT\n  }\n  is_stateful: true\n  control_output: \"Conv2D/ReadVariableOp\"\n}\nnode_def {\n  name: \"Conv2D/ReadVariableOp\"\n  op: \"ReadVariableOp\"\n  input: \"conv2d_readvariableop_resource\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D/ReadVariableOp\"\n  }\n}\nnode_def {\n  name: \"Conv2D\"\n  op: \"Conv2D\"\n  input: \"inputs\"\n  input: \"Conv2D/ReadVariableOp:value:0\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"data_format\"\n    value {\n      s: \"NHWC\"\n    }\n  }\n  attr {\n    key: \"dilations\"\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: \"explicit_paddings\"\n    value {\n      list {\n      }\n    }\n  }\n  attr {\n    key: \"padding\"\n    value {\n      s: \"SAME\"\n    }\n  }\n  attr {\n    key: \"strides\"\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: \"use_cudnn_on_gpu\"\n    value {\n      b: true\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D\"\n  }\n}\nnode_def {\n  name: \"Identity\"\n  op: \"Identity\"\n  input: \"Conv2D:output:0\"\n  input: \"^Conv2D/ReadVariableOp\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Identity\"\n  }\n}\nret {\n  key: \"identity\"\n  value: \"Identity:output:0\"\n}\nattr {\n  key: \"_construction_context\"\n  value {\n    s: \"kEagerRuntime\"\n  }\n}\ncontrol_ret {\n  key: \"Conv2D/ReadVariableOp\"\n  value: \"Conv2D/ReadVariableOp\"\n}\narg_attr {\n  key: 0\n  value {\n    attr {\n      key: \"_output_shapes\"\n      value {\n        list {\n          shape {\n            dim {\n              size: -1\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 128\n            }\n          }\n        }\n      }\n    }\n    attr {\n      key: \"_user_specified_name\"\n      value {\n        s: \"inputs\"\n      }\n    }\n  }\n}\n and current definition: signature {\n  name: \"__inference_conv_pw_4_layer_call_and_return_conditional_losses_165349\"\n  input_arg {\n    name: \"inputs\"\n    type: DT_FLOAT\n  }\n  input_arg {\n    name: \"conv2d_readvariableop_resource\"\n    type: DT_RESOURCE\n    handle_data {\n      dtype: DT_FLOAT\n      shape {\n        dim {\n          size: 1\n        }\n        dim {\n          size: 1\n        }\n        dim {\n          size: 128\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  output_arg {\n    name: \"identity\"\n    type: DT_FLOAT\n  }\n  is_stateful: true\n  control_output: \"Conv2D/ReadVariableOp\"\n}\nnode_def {\n  name: \"Conv2D/ReadVariableOp\"\n  op: \"ReadVariableOp\"\n  input: \"conv2d_readvariableop_resource\"\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: 1\n          }\n          dim {\n            size: 1\n          }\n          dim {\n            size: 128\n          }\n          dim {\n            size: 256\n          }\n        }\n      }\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D/ReadVariableOp\"\n  }\n}\nnode_def {\n  name: \"Conv2D\"\n  op: \"Conv2D\"\n  input: \"inputs\"\n  input: \"Conv2D/ReadVariableOp:value:0\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: -1\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 256\n          }\n        }\n      }\n    }\n  }\n  attr {\n    key: \"padding\"\n    value {\n      s: \"SAME\"\n    }\n  }\n  attr {\n    key: \"strides\"\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D\"\n  }\n}\nnode_def {\n  name: \"Identity\"\n  op: \"Identity\"\n  input: \"Conv2D:output:0\"\n  input: \"^Conv2D/ReadVariableOp\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: -1\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 256\n          }\n        }\n      }\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Identity\"\n  }\n}\nret {\n  key: \"identity\"\n  value: \"Identity:output:0\"\n}\nattr {\n  key: \"_construction_context\"\n  value {\n    s: \"kEagerRuntime\"\n  }\n}\nattr {\n  key: \"_input_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 6\n        }\n        dim {\n          size: 6\n        }\n        dim {\n          size: 128\n        }\n      }\n      shape {\n      }\n    }\n  }\n}\ncontrol_ret {\n  key: \"Conv2D/ReadVariableOp\"\n  value: \"Conv2D/ReadVariableOp\"\n}\narg_attr {\n  key: 0\n  value {\n    attr {\n      key: \"_output_shapes\"\n      value {\n        list {\n          shape {\n            dim {\n              size: -1\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 128\n            }\n          }\n        }\n      }\n    }\n    attr {\n      key: \"_user_specified_name\"\n      value {\n        s: \"inputs\"\n      }\n    }\n  }\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a4cf7ec64846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                           \u001b[0;34m'frozen_model.pb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                           \u001b[0minput_meta_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_saved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                           saved_model_tags)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py\u001b[0m in \u001b[0;36mfreeze_graph\u001b[0;34m(input_graph, input_saver, input_binary, input_checkpoint, output_node_names, restore_op_name, filename_tensor_name, output_graph, clear_devices, initializer_nodes, variable_names_whitelist, variable_names_blacklist, input_meta_graph, input_saved_model_dir, saved_model_tags, checkpoint_version)\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0minput_saved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaved_model_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m       checkpoint_version=checkpoint_version)\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py\u001b[0m in \u001b[0;36mfreeze_graph_with_def_protos\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_graph_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_saver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 instructions)\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    403\u001b[0m       \u001b[0mreturn_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m       producer_op_list=producer_op_list)\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[0;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m       \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;31m# Treat input mappings that don't appear in the graph as an error, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m       \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_function_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m       \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mdefinition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             self._function_deleter = _DefinedFunctionDeleter(\n\u001b[1;32m    329\u001b[0m                 fdef.signature.name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36madd_function\u001b[0;34m(fdef)\u001b[0m\n\u001b[1;32m   2436\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m   \u001b[0;34m\"\"\"Add a function definition to the context.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2438\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36madd_function\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \"\"\"\n\u001b[1;32m   1134\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextAddFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_function_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Attempting to add a duplicate function with name: __inference_conv_pw_4_layer_call_and_return_conditional_losses_165349 where the previous and current definitions differ. Previous definition: signature {\n  name: \"__inference_conv_pw_4_layer_call_and_return_conditional_losses_165349\"\n  input_arg {\n    name: \"inputs\"\n    type: DT_FLOAT\n  }\n  input_arg {\n    name: \"conv2d_readvariableop_resource\"\n    type: DT_RESOURCE\n  }\n  output_arg {\n    name: \"identity\"\n    type: DT_FLOAT\n  }\n  is_stateful: true\n  control_output: \"Conv2D/ReadVariableOp\"\n}\nnode_def {\n  name: \"Conv2D/ReadVariableOp\"\n  op: \"ReadVariableOp\"\n  input: \"conv2d_readvariableop_resource\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D/ReadVariableOp\"\n  }\n}\nnode_def {\n  name: \"Conv2D\"\n  op: \"Conv2D\"\n  input: \"inputs\"\n  input: \"Conv2D/ReadVariableOp:value:0\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"data_format\"\n    value {\n      s: \"NHWC\"\n    }\n  }\n  attr {\n    key: \"dilations\"\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: \"explicit_paddings\"\n    value {\n      list {\n      }\n    }\n  }\n  attr {\n    key: \"padding\"\n    value {\n      s: \"SAME\"\n    }\n  }\n  attr {\n    key: \"strides\"\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  attr {\n    key: \"use_cudnn_on_gpu\"\n    value {\n      b: true\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D\"\n  }\n}\nnode_def {\n  name: \"Identity\"\n  op: \"Identity\"\n  input: \"Conv2D:output:0\"\n  input: \"^Conv2D/ReadVariableOp\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Identity\"\n  }\n}\nret {\n  key: \"identity\"\n  value: \"Identity:output:0\"\n}\nattr {\n  key: \"_construction_context\"\n  value {\n    s: \"kEagerRuntime\"\n  }\n}\ncontrol_ret {\n  key: \"Conv2D/ReadVariableOp\"\n  value: \"Conv2D/ReadVariableOp\"\n}\narg_attr {\n  key: 0\n  value {\n    attr {\n      key: \"_output_shapes\"\n      value {\n        list {\n          shape {\n            dim {\n              size: -1\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 128\n            }\n          }\n        }\n      }\n    }\n    attr {\n      key: \"_user_specified_name\"\n      value {\n        s: \"inputs\"\n      }\n    }\n  }\n}\n and current definition: signature {\n  name: \"__inference_conv_pw_4_layer_call_and_return_conditional_losses_165349\"\n  input_arg {\n    name: \"inputs\"\n    type: DT_FLOAT\n  }\n  input_arg {\n    name: \"conv2d_readvariableop_resource\"\n    type: DT_RESOURCE\n    handle_data {\n      dtype: DT_FLOAT\n      shape {\n        dim {\n          size: 1\n        }\n        dim {\n          size: 1\n        }\n        dim {\n          size: 128\n        }\n        dim {\n          size: 256\n        }\n      }\n    }\n  }\n  output_arg {\n    name: \"identity\"\n    type: DT_FLOAT\n  }\n  is_stateful: true\n  control_output: \"Conv2D/ReadVariableOp\"\n}\nnode_def {\n  name: \"Conv2D/ReadVariableOp\"\n  op: \"ReadVariableOp\"\n  input: \"conv2d_readvariableop_resource\"\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: 1\n          }\n          dim {\n            size: 1\n          }\n          dim {\n            size: 128\n          }\n          dim {\n            size: 256\n          }\n        }\n      }\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D/ReadVariableOp\"\n  }\n}\nnode_def {\n  name: \"Conv2D\"\n  op: \"Conv2D\"\n  input: \"inputs\"\n  input: \"Conv2D/ReadVariableOp:value:0\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: -1\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 256\n          }\n        }\n      }\n    }\n  }\n  attr {\n    key: \"padding\"\n    value {\n      s: \"SAME\"\n    }\n  }\n  attr {\n    key: \"strides\"\n    value {\n      list {\n        i: 1\n        i: 1\n        i: 1\n        i: 1\n      }\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Conv2D\"\n  }\n}\nnode_def {\n  name: \"Identity\"\n  op: \"Identity\"\n  input: \"Conv2D:output:0\"\n  input: \"^Conv2D/ReadVariableOp\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_output_shapes\"\n    value {\n      list {\n        shape {\n          dim {\n            size: -1\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 6\n          }\n          dim {\n            size: 256\n          }\n        }\n      }\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"Identity\"\n  }\n}\nret {\n  key: \"identity\"\n  value: \"Identity:output:0\"\n}\nattr {\n  key: \"_construction_context\"\n  value {\n    s: \"kEagerRuntime\"\n  }\n}\nattr {\n  key: \"_input_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 6\n        }\n        dim {\n          size: 6\n        }\n        dim {\n          size: 128\n        }\n      }\n      shape {\n      }\n    }\n  }\n}\ncontrol_ret {\n  key: \"Conv2D/ReadVariableOp\"\n  value: \"Conv2D/ReadVariableOp\"\n}\narg_attr {\n  key: 0\n  value {\n    attr {\n      key: \"_output_shapes\"\n      value {\n        list {\n          shape {\n            dim {\n              size: -1\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 6\n            }\n            dim {\n              size: 128\n            }\n          }\n        }\n      }\n    }\n    attr {\n      key: \"_user_specified_name\"\n      value {\n        s: \"inputs\"\n      }\n    }\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "output_node_name = 'dense/Softmax'\n",
    "input_binary = False\n",
    "input_saver_def_path = False\n",
    "restore_op_name = None\n",
    "filename_tensor_name = None\n",
    "clear_devices = True\n",
    "input_meta_graph = False\n",
    "checkpoint_path = None\n",
    "input_graph_filename = None\n",
    "saved_model_tags = tag_constants.SERVING\n",
    "\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph_filename, input_saver_def_path,\n",
    "                          input_binary, checkpoint_path, output_node_name,\n",
    "                          restore_op_name, filename_tensor_name,\n",
    "                          'frozen_model.pb', clear_devices, \"\", \"\", \"\",\n",
    "                          input_meta_graph, input_saved_model_dir,\n",
    "                          saved_model_tags)\n",
    "\n",
    "\n",
    "tf_converter.convert('frozen_model.pb',\n",
    "                     'mobilenet.mlmodel',\n",
    "                     class_labels=EMOTIONS,\n",
    "                     image_input_names=['input_1:0'],\n",
    "                     output_feature_names=[output_node_name + ':0'],\n",
    "                     red_bias=-1,\n",
    "                     green_bias=-1,\n",
    "                     blue_bias=-1,\n",
    "                     image_scale=1/127.5,\n",
    "                     is_bgr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:34:55.510418Z",
     "start_time": "2019-05-26T14:34:52.149382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12827168"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "## Or from a SavedModel\n",
    "# converter = tf.lite.TFLiteConverter('./saved_model')\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"result.tflite\", \"wb\").write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflowjs\n",
      "  Downloading tensorflowjs-3.7.0-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 1.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorflow<3,>=2.1.0\n",
      "  Using cached tensorflow-2.5.0-cp36-cp36m-manylinux2010_x86_64.whl (454.3 MB)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflowjs) (1.15.0)\n",
      "Collecting tensorflow-hub<0.13,>=0.7.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.34.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/free/.local/lib/python3.6/site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
      "Collecting tensorboard~=2.5\n",
      "  Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: cached-property in /home/free/.local/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (57.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.30.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/free/.local/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/free/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/free/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/free/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/free/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/free/.local/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/free/.local/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2018.1.18)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/free/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: dataclasses in /home/free/.local/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/free/.local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.1)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-hub, tensorflow, tensorflowjs\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.14.0\n",
      "    Uninstalling tensorflow-estimator-1.14.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.14.0\n",
      "    Uninstalling tensorboard-1.14.0:\n",
      "      Successfully uninstalled tensorboard-1.14.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.14.0\n",
      "    Uninstalling tensorflow-1.14.0:\n",
      "      Successfully uninstalled tensorflow-1.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfcoreml 2.0 requires tensorflow<=1.14,>=1.5.0, but you have tensorflow 2.5.0 which is incompatible.\u001b[0m\n",
      "Successfully installed tensorboard-2.5.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 tensorflow-hub-0.12.0 tensorflowjs-3.7.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T14:35:48.595974Z",
     "start_time": "2019-05-26T14:35:48.591625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file my-tfjs/model.json...\r\n"
     ]
    }
   ],
   "source": [
    "# Convert in the current environment\n",
    "import sys\n",
    "!tensorflowjs_converter --input_format=tf_saved_model saved_model my-tfjs --output_format tfjs_graph_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
