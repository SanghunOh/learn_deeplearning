{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-30T13:32:40.795269Z","iopub.execute_input":"2024-10-30T13:32:40.795627Z","iopub.status.idle":"2024-10-30T13:32:41.827217Z","shell.execute_reply.started":"2024-10-30T13:32:40.795589Z","shell.execute_reply":"2024-10-30T13:32:41.825916Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"! python --version","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:34:03.381571Z","iopub.execute_input":"2024-10-30T13:34:03.381845Z","iopub.status.idle":"2024-10-30T13:34:04.386364Z","shell.execute_reply.started":"2024-10-30T13:34:03.381813Z","shell.execute_reply":"2024-10-30T13:34:04.385176Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Python 3.10.14\n","output_type":"stream"}]},{"cell_type":"code","source":"import platform \nplatform.platform()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:34:04.388406Z","iopub.execute_input":"2024-10-30T13:34:04.388734Z","iopub.status.idle":"2024-10-30T13:34:04.396886Z","shell.execute_reply.started":"2024-10-30T13:34:04.388699Z","shell.execute_reply":"2024-10-30T13:34:04.395807Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'Linux-5.15.154+-x86_64-with-glibc2.35'"},"metadata":{}}]},{"cell_type":"code","source":"!cat /etc/issue.net","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:34:04.398536Z","iopub.execute_input":"2024-10-30T13:34:04.399296Z","iopub.status.idle":"2024-10-30T13:34:05.442550Z","shell.execute_reply.started":"2024-10-30T13:34:04.399252Z","shell.execute_reply":"2024-10-30T13:34:05.441359Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Ubuntu 22.04.4 LTS\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:34:08.502890Z","iopub.execute_input":"2024-10-30T13:34:08.503341Z","iopub.status.idle":"2024-10-30T13:34:09.561510Z","shell.execute_reply.started":"2024-10-30T13:34:08.503295Z","shell.execute_reply":"2024-10-30T13:34:09.560208Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Wed Oct 30 13:34:09 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   29C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CPU VS. GPU","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-10-31T14:12:00.128781Z","iopub.execute_input":"2024-10-31T14:12:00.129437Z","iopub.status.idle":"2024-10-31T14:12:03.205005Z","shell.execute_reply.started":"2024-10-31T14:12:00.129394Z","shell.execute_reply":"2024-10-31T14:12:03.204218Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def cpu():\n    with torch.device('cpu'):\n        random_image_cpu = torch.randn((100, 3, 100, 100)) #랜덤한 이미지 100장 생성\n        net_cpu = torch.nn.Conv2d(3, 32, 7) (random_image_cpu) #2D convolution layer\n    return net_cpu.sum()\n\ndef gpu():\n    with torch.device('cuda'):\n        random_image_gpu = torch. randn( (100, 3, 100, 100))\n        net_gpu = torch.nn.Conv2d(3, 32, 7) (random_image_gpu)\n    return net_gpu.sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T14:12:38.495176Z","iopub.execute_input":"2024-10-31T14:12:38.495975Z","iopub.status.idle":"2024-10-31T14:12:38.501884Z","shell.execute_reply.started":"2024-10-31T14:12:38.495938Z","shell.execute_reply":"2024-10-31T14:12:38.500959Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import timeit\nprint('CPU(1st it) (s):')\ncpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\nprint(cpu_time)\nprint( 'CPU(2nd it) (s):')\ncpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\nprint(cpu_time)\nprint( 'CPU(3rd it) (s):')\ncpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\nprint(cpu_time)\nprint( 'GPU(1st it) (s):')\ngpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\nprint(gpu_time)\nprint( 'GPU(2nd it) (s):')\ngpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\nprint(gpu_time)\nprint( 'GPU(3rd it) (s):')\ngpu_time = timeit. timeit( 'gpu()', number=10, setup=\"from __main__ import gpu\")\nprint(gpu_time)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T14:13:05.219432Z","iopub.execute_input":"2024-10-31T14:13:05.220409Z","iopub.status.idle":"2024-10-31T14:13:10.223810Z","shell.execute_reply.started":"2024-10-31T14:13:05.220359Z","shell.execute_reply":"2024-10-31T14:13:10.222753Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"CPU(1st it) (s):\n1.4928231989999858\nCPU(2nd it) (s):\n1.5356093920000262\nCPU(3rd it) (s):\n1.9505605300000184\nGPU(1st it) (s):\n0.005292472999997244\nGPU(2nd it) (s):\n0.00478351700002122\nGPU(3rd it) (s):\n0.00429136700000754\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}