{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T15:33:40.275240Z",
     "start_time": "2019-04-28T15:33:40.269013Z"
    }
   },
   "source": [
    "<p style=\"border: 1px solid #e7692c; border-left: 15px solid #e7692c; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c\">Tip.</strong> <a style=\"color: #000000;\" href=\"https://nbviewer.jupyter.org/github/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/Chapter02/ch2_nb1_mnist_keras.ipynb\" title=\"View with Jupyter Online\">Click here to view this notebook on <code>nbviewer.jupyter.org</code></a>. \n",
    "    <br/>These notebooks are better read there, as Github default viewer ignores some of the formatting and interactive content.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "    <tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #363636; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #e7692c;\">Hands-on</span> Computer Vision with TensorFlow 2</span><br/>by <em>Eliot Andres</em> & <em>Benjamin Planche</em> (Packt Pub.)</strong><br/><br/>\n",
    "        <strong>> Chapter 2: TensorFlow Basics and Training a Model</strong><br/>\n",
    "    </p>\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #e7692c;\">Notebook 1:</small><br/>A simple computer vision model using Keras</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #363636; text-align:justify; padding: 0 10px;\">\n",
    "    In the second chapter of the book, we introduced the Keras API and how to build a simple model.\n",
    "    <br/>In this first notebook, we will therefore detail the related code snippets and results from the book.\n",
    "</p>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #e7692c; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c;\">Tip.</strong> The notebooks shared on this git repository illustrate some notions from the book \"<em><strong>Hands-on Computer Vision with TensorFlow 2</strong></em>\" written by Eliot Andres and Benjamin Planche, published by Packt. If you enjoyed the insights shared here, <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Learn more about the book!\"><strong>please consider acquiring the book!</strong></a>\n",
    "<br/><br/>\n",
    "The book provides further guidance for those eager to learn about computer vision and to harness the power of TensorFlow 2 and Keras to build efficient recognition systems for object detection, segmentation, video processing, smartphone applications, and more.</p>\n",
    "        </td>\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; width: 280px;\">\n",
    "    <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Learn more about the book!\" target=\"_blank\">\n",
    "        <img src=\"../banner_images/book_cover.png\" width=280>\n",
    "    </a>\n",
    "    <p style=\"background: #e7692c; color:#ffffff; padding: 10px; text-align:justify;\"><strong>Leverage deep learning to create powerful image processing apps with TensorFlow 2 and Keras. <br/></strong>Get the book for more insights!</p>\n",
    "    <ul style=\"height: 32px; white-space: nowrap; text-align: center; margin: 0px; padding: 0px; padding-top: 10px;\">\n",
    "    <li style=\"display: block;height: 100%;float: left;vertical-align: middle;margin: 0 25px 10px;padding: 0px;\">\n",
    "        <a href=\"https://www.amazon.com/Hands-Computer-Vision-TensorFlow-processing/dp/1788830644\" title=\"Get the book on Amazon (paperback or Kindle version)!\" target=\"_blank\">\n",
    "        <img style=\"vertical-align: middle; max-width: 72px; max-height: 32px;\" src=\"../banner_images/logo_amazon.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    <li style=\"display: inline-block;height: 100%;vertical-align: middle;float: right;margin: -5px 25px 10px;padding: 0px;\">\n",
    "        <a href=\"https://www.packtpub.com/application-development/hands-computer-vision-tensorflow-2\" title=\"Get your Packt book (paperback, PDF, ePUB, or MOBI version)!\" target=\"_blank\">\n",
    "        <img style=\"vertical-align: middle; max-width: 72px; max-height: 32px;\" src=\"../banner_images/logo_packt.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    </ul>\n",
    "        </td>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:43:45.756874Z",
     "start_time": "2019-05-16T11:43:44.798323Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:43:46.132993Z",
     "start_time": "2019-05-16T11:43:45.757994Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "num_channels = 1\n",
    "input_shape = (img_rows, img_cols, num_channels)\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T11:43:46.150349Z",
     "start_time": "2019-05-16T11:43:46.134258Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T13:52:39.124524Z",
     "start_time": "2019-05-14T13:51:49.141572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.4245 - accuracy: 0.1250WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1875 [..............................] - ETA: 1:33 - loss: 2.4084 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0985s). Check your callbacks.\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6551 - accuracy: 0.8313 - val_loss: 0.3603 - val_accuracy: 0.9024\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3395 - accuracy: 0.9052 - val_loss: 0.2944 - val_accuracy: 0.9193\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2900 - accuracy: 0.9180 - val_loss: 0.2595 - val_accuracy: 0.9274\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2594 - accuracy: 0.9271 - val_loss: 0.2380 - val_accuracy: 0.9339\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2364 - accuracy: 0.9336 - val_loss: 0.2189 - val_accuracy: 0.9369\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2183 - accuracy: 0.9388 - val_loss: 0.2050 - val_accuracy: 0.9412\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2031 - accuracy: 0.9429 - val_loss: 0.1924 - val_accuracy: 0.9457\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1899 - accuracy: 0.9465 - val_loss: 0.1815 - val_accuracy: 0.9482\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1784 - accuracy: 0.9505 - val_loss: 0.1729 - val_accuracy: 0.9508\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1685 - accuracy: 0.9529 - val_loss: 0.1630 - val_accuracy: 0.9537\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1596 - accuracy: 0.9548 - val_loss: 0.1574 - val_accuracy: 0.9545\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1514 - accuracy: 0.9575 - val_loss: 0.1495 - val_accuracy: 0.9567\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1441 - accuracy: 0.9598 - val_loss: 0.1443 - val_accuracy: 0.9579\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1376 - accuracy: 0.9612 - val_loss: 0.1396 - val_accuracy: 0.9606\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1317 - accuracy: 0.9636 - val_loss: 0.1341 - val_accuracy: 0.9622\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1263 - accuracy: 0.9650 - val_loss: 0.1298 - val_accuracy: 0.9632\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1212 - accuracy: 0.9661 - val_loss: 0.1261 - val_accuracy: 0.9635\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1166 - accuracy: 0.9682 - val_loss: 0.1221 - val_accuracy: 0.9637\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1122 - accuracy: 0.9693 - val_loss: 0.1175 - val_accuracy: 0.9656\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1082 - accuracy: 0.9702 - val_loss: 0.1175 - val_accuracy: 0.9664\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9715 - val_loss: 0.1130 - val_accuracy: 0.9665\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1008 - accuracy: 0.9717 - val_loss: 0.1135 - val_accuracy: 0.9674\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0975 - accuracy: 0.9733 - val_loss: 0.1100 - val_accuracy: 0.9681\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0944 - accuracy: 0.9736 - val_loss: 0.1067 - val_accuracy: 0.9678\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0914 - accuracy: 0.9750 - val_loss: 0.1035 - val_accuracy: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x163c70d00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "callbacks = [tf.keras.callbacks.TensorBoard('./keras')]\n",
    "model.fit(x_train, y_train, epochs=25, verbose=1, validation_data=(x_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T11:04:31.961895Z",
     "start_time": "2019-04-29T11:04:31.956592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/keras.py:220: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './estimator_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.keras.estimator.model_to_estimator(model, model_dir='./estimator_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T11:05:35.649548Z",
     "start_time": "2019-04-29T11:04:32.510795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./estimator_dir/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ./estimator_dir/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 4 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./estimator_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.028037764, step = 0\n",
      "INFO:tensorflow:global_step/sec: 120.462\n",
      "INFO:tensorflow:loss = 0.069045104, step = 100 (0.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.805\n",
      "INFO:tensorflow:loss = 0.077392004, step = 200 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.724\n",
      "INFO:tensorflow:loss = 0.0442048, step = 300 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.646\n",
      "INFO:tensorflow:loss = 0.07756476, step = 400 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.088\n",
      "INFO:tensorflow:loss = 0.119972244, step = 500 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.959\n",
      "INFO:tensorflow:loss = 0.052289195, step = 600 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.961\n",
      "INFO:tensorflow:loss = 0.017171226, step = 700 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.996\n",
      "INFO:tensorflow:loss = 0.0663753, step = 800 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.588\n",
      "INFO:tensorflow:loss = 0.03535405, step = 900 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.367\n",
      "INFO:tensorflow:loss = 0.15453753, step = 1000 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.824\n",
      "INFO:tensorflow:loss = 0.09011651, step = 1100 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.672\n",
      "INFO:tensorflow:loss = 0.07644805, step = 1200 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.616\n",
      "INFO:tensorflow:loss = 0.072343595, step = 1300 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.362\n",
      "INFO:tensorflow:loss = 0.066372596, step = 1400 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.019\n",
      "INFO:tensorflow:loss = 0.07390976, step = 1500 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.315\n",
      "INFO:tensorflow:loss = 0.103614435, step = 1600 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.628\n",
      "INFO:tensorflow:loss = 0.021431439, step = 1700 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.927\n",
      "INFO:tensorflow:loss = 0.11552451, step = 1800 (0.268 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1875...\n",
      "INFO:tensorflow:Saving checkpoints for 1875 into ./estimator_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1875...\n",
      "INFO:tensorflow:Loss for final step: 0.033828452.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x16621e610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "def train_input_fn():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE).repeat()\n",
    "    return train_dataset\n",
    "\n",
    "estimator.train(train_input_fn, steps=len(x_train)//BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
